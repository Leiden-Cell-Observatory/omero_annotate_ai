{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMERO Micro-SAM Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omero_annotate_ai\n",
    "from omero_annotate_ai import (\n",
    "    create_omero_connection_widget,\n",
    "    create_workflow_widget,\n",
    "    create_pipeline,\n",
    ")\n",
    "\n",
    "from omero_annotate_ai.core.config import load_config_from_yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"omero-annotate-ai version: {omero_annotate_ai.__version__}\")\n",
    "\n",
    "try:\n",
    "    import ezomero\n",
    "    print(\"OMERO functionality: Available\")\n",
    "except ImportError:\n",
    "    print(\"OMERO functionality: Install with: pip install -e .[omero]\")\n",
    "\n",
    "try:\n",
    "    import keyring\n",
    "    print(\"Keyring support: Available\")\n",
    "except ImportError:\n",
    "    print(\"Keyring support: Not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMERO Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_widget = create_omero_connection_widget()\n",
    "conn_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = conn_widget.get_connection()\n",
    "\n",
    "if conn is None:\n",
    "    raise ConnectionError(\"No OMERO connection established\")\n",
    "\n",
    "print(f\"Connected as: {conn.getUser().getName()}\")\n",
    "print(f\"Group: {conn.getGroupFromContext().getName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the enhanced configuration widget with table management\n",
    "workflow_widget = create_workflow_widget(connection=conn)\n",
    "workflow_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config_from_yaml(\n",
    "    \"C:\\\\Users\\\\Maarten\\\\AppData\\Local\\Temp\\\\omero_annotations_m_14q2cq\\\\annotation_config.yaml\"\n",
    ")\n",
    "print(f\"Container: {config.omero.container_type} (ID: {config.omero.container_id})\")\n",
    "print(f\"Training Set: {config.training.trainingset_name}\")\n",
    "print(f\"Model: {config.micro_sam.model_type}\")\n",
    "print(f\"Output: {config.batch_processing.output_folder}\")\n",
    "\n",
    "if config.patches.use_patches:\n",
    "    print(f\"Patches: {config.patches.patches_per_image} per image ({config.patches.patch_size[0]}Ã—{config.patches.patch_size[1]})\")\n",
    "\n",
    "print(f\"Scope: {'All images' if config.training.segment_all else f'{config.training.train_n} training + {config.training.validate_n} validation'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = create_pipeline(config, conn)\n",
    "\n",
    "container = conn.getObject(config.omero.container_type.capitalize(), config.omero.container_id)\n",
    "if container is None:\n",
    "    raise ValueError(f\"{config.omero.container_type} with ID {config.omero.container_id} not found\")\n",
    "\n",
    "print(f\"Container: {container.getName()}\")\n",
    "\n",
    "images_list = pipeline.get_images_from_container()\n",
    "print(f\"Images to process: {len(images_list)}\")\n",
    "\n",
    "for i, img in enumerate(images_list[:3]):\n",
    "    print(f\"  {i+1}. {img.getName()} (ID: {img.getId()})\")\n",
    "if len(images_list) > 3:\n",
    "    print(f\"  ... and {len(images_list) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create annotation table\n",
    "table_id, images_list = pipeline.create_annotation_table(images_list)\n",
    "print(f\"Table created with ID: {table_id}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Run annotation processing\n",
    "table_id, processed_images = pipeline.run_annotation(table_id, images_list)\n",
    "\n",
    "print(f\"Completed. Processed {len(processed_images)} images\")\n",
    "print(f\"Table ID: {table_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Set: {config.training.trainingset_name}\")\n",
    "print(f\"Table ID: {table_id}\")\n",
    "print(f\"Images Processed: {len(processed_images)}\")\n",
    "print(f\"Output: {config.batch_processing.output_folder}\")\n",
    "\n",
    "if processed_images:\n",
    "    print(f\"Processed Images:\")\n",
    "    for i, img in enumerate(processed_images[:5]):\n",
    "        if hasattr(img, 'getName'):\n",
    "            print(f\"  {i+1}. {img.getName()} (ID: {img.getId()})\")\n",
    "        else:\n",
    "            img_obj = conn.getObject(\"Image\", img)\n",
    "            if img_obj:\n",
    "                print(f\"  {i+1}. {img_obj.getName()} (ID: {img})\")\n",
    "    \n",
    "    if len(processed_images) > 5:\n",
    "        print(f\"  ... and {len(processed_images) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = f\"annotation_config_{config.training.trainingset_name}.yaml\"\n",
    "config_path = Path(config.batch_processing.output_folder) / config_filename\n",
    "\n",
    "try:\n",
    "    config.save_yaml(config_path)\n",
    "    print(f\"Config saved: {config_path}\")\n",
    "except Exception as e:\n",
    "    config.save_yaml(config_filename)\n",
    "    print(f\"Config saved: {config_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'conn' in locals() and conn is not None:\n",
    "    conn.close()\n",
    "    print(\"OMERO connection closed\")\n",
    "\n",
    "print(f\"Total images processed: {len(processed_images) if 'processed_images' in locals() else 0}\")\n",
    "print(f\"Table ID: {table_id if 'table_id' in locals() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Options\n",
    "\n",
    "```python\n",
    "# Option 1: Full workflow\n",
    "table_id, processed_images = pipeline.run_full_workflow()\n",
    "\n",
    "# Option 2: Split workflow\n",
    "table_id, images_list = pipeline.create_annotation_table()\n",
    "table_id, processed_images = pipeline.run_annotation(table_id, images_list)\n",
    "\n",
    "# Option 3: Resume from existing table\n",
    "table_id, processed_images = pipeline.run_annotation(existing_table_id)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
