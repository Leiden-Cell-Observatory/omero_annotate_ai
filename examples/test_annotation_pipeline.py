#!/usr/bin/env python3
"""
Test script for the omero-annotate-ai package annotation pipeline.

This script replicates the functionality of the Jupyter notebook 
omero-annotate-ai-batch.ipynb in a standalone Python script format.

Usage:
    python test_annotation_pipeline.py [config.yaml]
    
If no config file is provided, it will use test_config.yaml
"""

import sys
import os
import tempfile
import shutil
import argparse
from pathlib import Path
from getpass import getpass
from dotenv import load_dotenv

def main():
    parser = argparse.ArgumentParser(description='Test omero-annotate-ai annotation pipeline')
    parser.add_argument('config', nargs='?', default='test_config.yaml',
                       help='YAML configuration file (default: test_config.yaml)')
    parser.add_argument('--dry-run', action='store_true',
                       help='Validate configuration without running the pipeline')
    parser.add_argument('--output-dir', type=str,
                       help='Override output directory')
    args = parser.parse_args()

    print("ğŸš€ OMERO Micro-SAM Annotation Pipeline Test")
    print("=" * 50)

    # 1. Import the package
    print("\nğŸ“¦ Importing omero-annotate-ai package...")
    try:
        import omero_annotate_ai
        from omero_annotate_ai.core.config import AnnotationConfig
        from omero_annotate_ai.core.pipeline import create_pipeline
        print(f"âœ… Package version: {omero_annotate_ai.__version__}")
    except ImportError as e:
        print(f"âŒ Failed to import omero-annotate-ai: {e}")
        print("ğŸ’¡ Install the package with: pip install -e .[omero]")
        sys.exit(1)

    # 2. Check OMERO dependencies
    print("\nğŸ”— Checking OMERO dependencies...")
    try:
        import omero
        from omero.gateway import BlitzGateway
        import ezomero
        print("âœ… OMERO functionality available")
        OMERO_AVAILABLE = True
    except ImportError as e:
        print(f"âŒ OMERO functionality not available: {e}")
        print("ğŸ’¡ Install with: pip install -e .[omero]")
        if not args.dry_run:
            sys.exit(1)
        OMERO_AVAILABLE = False

    # 3. Load configuration
    print(f"\nğŸ“„ Loading configuration from {args.config}...")
    config_path = Path(args.config)
    if not config_path.exists():
        print(f"âŒ Configuration file not found: {config_path}")
        sys.exit(1)
    
    try:
        config = AnnotationConfig.from_yaml(str(config_path))
        print("âœ… Configuration loaded successfully")
    except Exception as e:
        print(f"âŒ Failed to load configuration: {e}")
        sys.exit(1)

    # 4. Validate configuration
    print("\nğŸ” Validating configuration...")
    try:
        config.validate()
        print("âœ… Configuration is valid")
    except Exception as e:
        print(f"âŒ Configuration validation failed: {e}")
        sys.exit(1)

    # 5. Display configuration summary
    print("\nğŸ“‹ Configuration Summary:")
    print(f"   ğŸ”¬ Model: {config.microsam.model_type}")
    print(f"   ğŸ“¦ Container: {config.omero.container_type} (ID: {config.omero.container_id})")
    print(f"   ğŸ“º Channel: {config.omero.channel}")
    print(f"   ğŸ¯ Training Set: {config.training.trainingset_name}")
    print(f"   ğŸ“Š Batch Size: {config.batch_processing.batch_size}")
    print(f"   ğŸ§© Use Patches: {config.patches.use_patches}")
    if config.patches.use_patches:
        print(f"   ğŸ“ Patch Size: {config.patches.patch_size}")
    print(f"   ğŸ”„ Resume from Table: {config.workflow.resume_from_table}")
    print(f"   ğŸ“– Read-only Mode: {config.workflow.read_only_mode}")
    print(f"   ğŸ§  3D Processing: {config.microsam.three_d}")

    # Override output directory if specified
    if args.output_dir:
        config.batch_processing.output_folder = args.output_dir
        print(f"ğŸ“ Output directory overridden: {args.output_dir}")
    else:
        # Create temporary output directory
        output_directory = tempfile.mkdtemp()
        config.batch_processing.output_folder = output_directory
        print(f"ğŸ“ Created temporary output directory: {output_directory}")

    if args.dry_run:
        print("\nâœ… Dry run completed successfully!")
        print("ğŸ” Configuration is valid and ready for use")
        return

    if not OMERO_AVAILABLE:
        print("âŒ Cannot run pipeline without OMERO functionality")
        sys.exit(1)

    # 6. Setup OMERO connection
    print("\nğŸ” Setting up OMERO connection...")
    load_dotenv(override=True)
    
    # Get credentials
    host = os.environ.get("HOST")
    username = os.environ.get("USER_NAME") 
    group = os.environ.get("GROUP")
    password = os.environ.get("PASSWORD")
    
    if not host or not username:
        print("âŒ Missing OMERO credentials in environment")
        print("ğŸ’¡ Create a .env file with HOST, USER_NAME, and GROUP")
        sys.exit(1)
    
    if not password:
        password = getpass("Enter OMERO server password: ")
    
    # Connect to OMERO
    conn = BlitzGateway(
        host=host,
        username=username,
        passwd=password,
        group=group,
        secure=True
    )
    
    connection_status = conn.connect()
    if connection_status:
        print("âœ… Connected to OMERO Server")
        print(f"ğŸ‘¤ User: {conn.getUser().getName()}")
        print(f"ğŸ¢ Group: {conn.getGroupFromContext().getName()}")
    else:
        print("âŒ Connection to OMERO Server Failed")
        sys.exit(1)
    
    conn.c.enableKeepAlive(60)

    try:
        # 7. Create pipeline and validate container
        print("\nğŸ—ï¸ Creating annotation pipeline...")
        pipeline = create_pipeline(config, conn)
        
        # 8. Get container details and preview images
        print("\nğŸ“‚ Validating container and getting image list...")
        container_type = config.omero.container_type
        container_id = config.omero.container_id
        
        # Validate container exists
        if container_type == "dataset":
            container = conn.getObject("Dataset", container_id)
            if container is None:
                raise ValueError(f"Dataset with ID {container_id} not found")
            print(f"ğŸ“ Dataset: {container.getName()} (ID: {container_id})")
        elif container_type == "project":
            container = conn.getObject("Project", container_id)
            if container is None:
                raise ValueError(f"Project with ID {container_id} not found")
            print(f"ğŸ“‚ Project: {container.getName()} (ID: {container_id})")
        elif container_type == "plate":
            container = conn.getObject("Plate", container_id)
            if container is None:
                raise ValueError(f"Plate with ID {container_id} not found")
            print(f"ğŸ§ª Plate: {container.getName()} (ID: {container_id})")
        elif container_type == "image":
            container = conn.getObject("Image", container_id)
            if container is None:
                raise ValueError(f"Image with ID {container_id} not found")
            print(f"ğŸ–¼ï¸ Image: {container.getName()} (ID: {container_id})")
        else:
            raise ValueError(f"Unsupported container type: {container_type}")
        
        # Get images list
        images_list = pipeline.get_images_from_container()
        print(f"ğŸ“Š Found {len(images_list)} images to process")
        
        # Show first few images
        print("\nğŸ–¼ï¸ Sample images:")
        for i, img in enumerate(images_list[:3]):
            print(f"   {i+1}. {img.getName()} (ID: {img.getId()})")
        if len(images_list) > 3:
            print(f"   ... and {len(images_list) - 3} more images")

        # 9. Run the annotation pipeline
        print(f"\nğŸš€ Starting annotation pipeline...")
        print(f"   Processing {len(images_list)} images using micro-SAM")
        print(f"   Model: {config.microsam.model_type}")
        print(f"   Napari will open for interactive annotation")
        
        # Run the complete workflow
        table_id, processed_images = pipeline.run_full_workflow()
        
        print(f"\nâœ… Annotation pipeline completed successfully!")
        print(f"ğŸ“Š Processed {len(processed_images)} images")
        print(f"ğŸ“‹ Tracking table ID: {table_id}")
        
        if config.workflow.read_only_mode:
            print(f"ğŸ’¾ Annotations saved locally to: {config.workflow.local_output_dir}")
        else:
            print(f"â˜ï¸ Annotations uploaded to OMERO")

        # 10. Display results
        print("\nğŸ“Š Checking results...")
        if table_id is not None:
            try:
                tracking_df = ezomero.get_table(conn, table_id)
                print(f"ğŸ“‹ Tracking table contains {len(tracking_df)} rows")
                print(f"âœ… Processed: {tracking_df['processed'].sum()} units")
                print(f"â³ Pending: {(~tracking_df['processed']).sum()} units")
                
                if not config.training.segment_all:
                    train_count = tracking_df['train'].sum()
                    validate_count = tracking_df['validate'].sum()
                    print(f"ğŸ“ Training samples: {train_count}")
                    print(f"âœ… Validation samples: {validate_count}")
                    
            except Exception as e:
                print(f"âš ï¸ Could not retrieve tracking table details: {e}")

        # 11. Save configuration with results
        results_config_path = f"results_config_{config.training.trainingset_name}.yaml"
        config.save_yaml(results_config_path)
        print(f"ğŸ’¾ Configuration with results saved to: {results_config_path}")

    except Exception as e:
        print(f"âŒ Error during pipeline execution: {e}")
        raise
    finally:
        # 12. Clean up
        print("\nğŸ§¹ Cleaning up...")
        
        # Clean up temporary directory if we created one
        if not args.output_dir and 'output_directory' in locals():
            try:
                shutil.rmtree(output_directory)
                print(f"ğŸ—‘ï¸ Removed temporary directory: {output_directory}")
            except Exception as e:
                print(f"âš ï¸ Error removing temporary directory: {e}")
        
        # Close OMERO connection
        if 'conn' in locals() and conn is not None:
            conn.close()
            print("ğŸ”Œ OMERO connection closed")

    print("\nâœ¨ Test completed successfully!")
    print(f"ğŸ“„ Configuration used: {args.config}")
    if table_id:
        print(f"ğŸ“‹ OMERO tracking table ID: {table_id}")


if __name__ == "__main__":
    main()