{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro-SAM Training from OMERO Data\n",
    "\n",
    "Train micro-SAM models using annotation tables from OMERO with automated data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available functions: Connection, Training Data, Training Utils\n"
     ]
    }
   ],
   "source": [
    "# Import the package with training convenience functions\n",
    "from omero_annotate_ai import (\n",
    "    create_omero_connection_widget,\n",
    "    create_training_data_widget,\n",
    "    prepare_training_data_from_table,\n",
    "    setup_training,    # Convenience function for training setup\n",
    "    run_training       # Convenience function for training execution\n",
    ")\n",
    "\n",
    "# Additional imports\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "print(f\"Available functions: Connection, Training Data, Training Utils\")\n",
    "#print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OMERO Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded configuration from connection history: root@localhost\n",
      "üîê Password loaded from keychain (no expiration)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e607161955347999311a3deb77a983f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üîå OMERO Server Connection</h3>', layout=Layout(margin='0 0 20px 0')), HTML(valu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display OMERO connection widget\n",
    "conn_widget = create_omero_connection_widget()\n",
    "conn_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to OMERO as: root\n"
     ]
    }
   ],
   "source": [
    "# Get the OMERO connection\n",
    "conn = conn_widget.get_connection()\n",
    "\n",
    "if conn is None:\n",
    "    raise ConnectionError(\"No OMERO connection established.\")\n",
    "\n",
    "print(f\"Connected to OMERO as: {conn.getUser().getName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ca879dca3f437eb7a046ff6dd4b5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üéØ Training Data Selection</h3>', layout=Layout(margin='0 0 20px 0')), HTML(valu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create training data selection widget\n",
    "training_widget = create_training_data_widget(connection=conn)\n",
    "training_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected training table:\n",
      "  Table ID: 1508\n",
      "  Table Name: micro_sam_training_micro_sam_foci_test_20250825_201655\n",
      "  Created: Unknown\n"
     ]
    }
   ],
   "source": [
    "# Get selected training table\n",
    "selected_table_id = training_widget.get_selected_table_id()\n",
    "selected_table_info = training_widget.get_selected_table_info()\n",
    "\n",
    "if selected_table_id:\n",
    "    print(f\"Selected training table:\")\n",
    "    print(f\"  Table ID: {selected_table_id}\")\n",
    "    print(f\"  Table Name: {selected_table_info.get('name', 'Unknown')}\")\n",
    "    print(f\"  Created: {selected_table_info.get('created', 'Unknown')}\")\n",
    "else:\n",
    "    raise ValueError(\"No training table selected. Please select a table above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Training Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training output directory: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for training\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "home_dir = Path.home()\n",
    "models_dir = home_dir / \"micro-sam_models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "folder_name = f\"micro-sam-{timestamp}\"\n",
    "output_directory = models_dir / folder_name\n",
    "output_directory.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Training output directory: {output_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Automated Data Preparation\n",
    "\n",
    "Use the automated data preparation function to download and organize training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded table with 6 rows\n",
      "Table saved to: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\table_1508.csv\n",
      "‚úÖ Using 6 processed rows for training\n",
      "Optional columns found: ['is_volumetric']\n",
      "Table schema validated for processing\n",
      "Using 3 training images and 3 validation images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing training data:   0%|          | 0/3 [00:00<?, ?it/s]INFO:omero.gateway:Registered b83f12d0-8571-4503-bca6-acbfbc6cb054/9a67932c-4c66-45bb-a0a2-9f5a3682c2d7omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0 - Image ID: 459, Patch: False, Dimensions: 0x0 at (271,456), Volumetric: False\n",
      "  2D Full Image Request - start_coords: (0, 0, 0, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered b83f12d0-8571-4503-bca6-acbfbc6cb054/9a67932c-4c66-45bb-a0a2-9f5a3682c2d7omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n",
      "Preparing training data:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.46it/s]INFO:omero.gateway:Registered b83f12d0-8571-4503-bca6-acbfbc6cb054/573be73d-5a37-4c74-85ec-115b14af9f64omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (1024, 1024, 1, 4, 1)\n",
      "  Extracted 2D shape: (1024, 1024)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\training_input\\input_00000.tif with shape (1024, 1024)\n",
      "  Attempting to download label with ID: 1502\n",
      "  File annotation found: seg_00000.tif\n",
      "  Label shape: (512, 512) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\training_label\\label_00000.tif\n",
      "Item 1 - Image ID: 453, Patch: False, Dimensions: 0x0 at (386,454), Volumetric: False\n",
      "  2D Full Image Request - start_coords: (0, 0, 0, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered b83f12d0-8571-4503-bca6-acbfbc6cb054/573be73d-5a37-4c74-85ec-115b14af9f64omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n",
      "Preparing training data:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.54it/s]INFO:omero.gateway:Registered b83f12d0-8571-4503-bca6-acbfbc6cb054/4a391d4b-1ca8-4bff-9880-ae80f45b3102omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (1024, 1024, 1, 4, 1)\n",
      "  Extracted 2D shape: (1024, 1024)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\training_input\\input_00001.tif with shape (1024, 1024)\n",
      "  Attempting to download label with ID: 1503\n",
      "  File annotation found: seg_00001.tif\n",
      "  Label shape: (512, 512) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\training_label\\label_00001.tif\n",
      "Item 2 - Image ID: 455, Patch: False, Dimensions: 0x0 at (391,204), Volumetric: False\n",
      "  2D Full Image Request - start_coords: (0, 0, 0, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered b83f12d0-8571-4503-bca6-acbfbc6cb054/4a391d4b-1ca8-4bff-9880-ae80f45b3102omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n",
      "Preparing training data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (1024, 1024, 1, 4, 1)\n",
      "  Extracted 2D shape: (1024, 1024)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\training_input\\input_00002.tif with shape (1024, 1024)\n",
      "  Attempting to download label with ID: 1504\n",
      "  File annotation found: seg_00002.tif\n",
      "  Label shape: (512, 512) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\training_label\\label_00002.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing val data:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0 - Image ID: 451, Patch: False, Dimensions: 0x0 at (479,123), Volumetric: False\n",
      "  2D Full Image Request - start_coords: (0, 0, 0, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered b83f12d0-8571-4503-bca6-acbfbc6cb054/7498a118-6f3a-443d-a915-6f5ee9c243b8omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n",
      "INFO:omero.gateway:Unregistered b83f12d0-8571-4503-bca6-acbfbc6cb054/7498a118-6f3a-443d-a915-6f5ee9c243b8omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n",
      "Preparing val data:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:01,  1.60it/s]INFO:omero.gateway:Registered b83f12d0-8571-4503-bca6-acbfbc6cb054/f7164932-415b-438d-b6e7-5bad7ef27983omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (1024, 1024, 1, 4, 1)\n",
      "  Extracted 2D shape: (1024, 1024)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\val_input\\input_00000.tif with shape (1024, 1024)\n",
      "  Attempting to download label with ID: 1505\n",
      "  File annotation found: seg_00003.tif\n",
      "  Label shape: (512, 512) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\val_label\\label_00000.tif\n",
      "Item 1 - Image ID: 454, Patch: False, Dimensions: 0x0 at (356,470), Volumetric: False\n",
      "  2D Full Image Request - start_coords: (0, 0, 0, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered b83f12d0-8571-4503-bca6-acbfbc6cb054/f7164932-415b-438d-b6e7-5bad7ef27983omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n",
      "Preparing val data:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:01<00:00,  1.56it/s]INFO:omero.gateway:Registered b83f12d0-8571-4503-bca6-acbfbc6cb054/96f5625c-e380-4163-937b-9111852c5171omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (1024, 1024, 1, 4, 1)\n",
      "  Extracted 2D shape: (1024, 1024)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\val_input\\input_00001.tif with shape (1024, 1024)\n",
      "  Attempting to download label with ID: 1506\n",
      "  File annotation found: seg_00004.tif\n",
      "  Label shape: (512, 512) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\val_label\\label_00001.tif\n",
      "Item 2 - Image ID: 456, Patch: False, Dimensions: 0x0 at (425,94), Volumetric: False\n",
      "  2D Full Image Request - start_coords: (0, 0, 0, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered b83f12d0-8571-4503-bca6-acbfbc6cb054/96f5625c-e380-4163-937b-9111852c5171omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 34317 -t 60000\n",
      "Preparing val data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (1024, 1024, 1, 4, 1)\n",
      "  Extracted 2D shape: (1024, 1024)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\val_input\\input_00002.tif with shape (1024, 1024)\n",
      "  Attempting to download label with ID: 1507\n",
      "  File annotation found: seg_00005.tif\n",
      "  Label shape: (512, 512) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\val_label\\label_00002.tif\n",
      "‚úÖ Training data prepared successfully in: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\n",
      "Statistics: {'n_training_images': 3, 'n_training_labels': 3, 'n_val_images': 3, 'n_val_labels': 3, 'total_rows_processed': 6}\n",
      "\n",
      "Training data preparation completed successfully!\n",
      "\n",
      "Dataset statistics:\n",
      "  n_training_images: 3\n",
      "  n_training_labels: 3\n",
      "  n_val_images: 3\n",
      "  n_val_labels: 3\n",
      "  total_rows_processed: 6\n",
      "\n",
      "Directory structure created:\n",
      "  Training images: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\training_input\n",
      "  Training labels: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\training_label\n",
      "  Validation images: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\val_input\n",
      "  Validation labels: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\val_label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run automated data preparation\n",
    "try:\n",
    "    training_result = prepare_training_data_from_table(\n",
    "        conn=conn,\n",
    "        table_id=selected_table_id,\n",
    "        output_dir=output_directory,\n",
    "        validation_split=0.2,  # 20% for validation\n",
    "        clean_existing=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining data preparation completed successfully!\")\n",
    "    print(f\"\\nDataset statistics:\")\n",
    "    for key, value in training_result['stats'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Store paths for later use in training\n",
    "    training_input_dir = training_result['training_input']\n",
    "    training_label_dir = training_result['training_label']\n",
    "    val_input_dir = training_result['val_input']\n",
    "    val_label_dir = training_result['val_label']\n",
    "    \n",
    "    print(f\"\\nDirectory structure created:\")\n",
    "    print(f\"  Training images: {training_input_dir}\")\n",
    "    print(f\"  Training labels: {training_label_dir}\")\n",
    "    print(f\"  Validation images: {val_input_dir}\")\n",
    "    print(f\"  Validation labels: {val_label_dir}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during data preparation: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Micro-SAM Training Setup\n",
    "\n",
    "Configure and run micro-SAM training using the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration prepared!\n",
      "Model name: micro_sam_training_20250825_203206\n",
      "Output directory: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\n",
      "Training epochs: 10\n",
      "Calculated iterations: 30\n"
     ]
    }
   ],
   "source": [
    "# ‚ú® Setup training configuration using convenience function\n",
    "training_config = setup_training(\n",
    "    training_result,\n",
    "    epochs=10,               # Primary parameter: number of epochs (use 50+ for real training)\n",
    "    batch_size=1,            # Adjust based on GPU memory\n",
    "    learning_rate=1e-5,      # Conservative learning rate\n",
    "    patch_shape=(512, 512),  # Input patch size\n",
    "    model_type=\"vit_b\",       # SAM model variant\n",
    "    n_objects_per_batch=25   # Objects per batch for sampling\n",
    ")\n",
    "\n",
    "print(\"Training configuration prepared!\")\n",
    "print(f'Model name: {training_config[\"model_name\"]}')\n",
    "print(f'Output directory: {training_config[\"output_dir\"]}')\n",
    "print(f'Training epochs: {training_config[\"epochs\"]}')\n",
    "print(f'Calculated iterations: {training_config[\"n_iterations\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting micro-SAM training...\n",
      "Starting micro-SAM training...\n",
      "Model name: micro_sam_training_20250825_203206\n",
      "Model type: vit_b\n",
      "Training configuration:\n",
      "  Patch shape: (512, 512)\n",
      "  Batch size: 1\n",
      "  Learning rate: 1e-05\n",
      "  Epochs: 10\n",
      "  Objects per batch: 25\n",
      "  Checkpoint folder: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250825_203144\\checkpoints\n",
      "  Using patch shape: (1, 512, 512)\n",
      "Training device: cpu\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "(3, 1024, 1024), (3, 512, 512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ‚ú® Execute training with convenience function\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting micro-SAM training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m training_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124müéâ Training completed successfully!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Results:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\processing\\training_utils.py:144\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(training_config, framework)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03mExecute training with framework-specific implementation.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    ImportError: If required framework packages are not available\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosam\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_microsam_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     supported_frameworks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosam\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\processing\\training_utils.py:211\u001b[0m, in \u001b[0;36m_run_microsam_training\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Create data loaders with correct API\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43msam_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_sam_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_segmentation_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_instance_segmentation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_shape_3d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_seg_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msam_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m sam_training\u001b[38;5;241m.\u001b[39mdefault_sam_loader(\n\u001b[0;32m    226\u001b[0m     raw_paths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_input\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    227\u001b[0m     raw_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m     sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[0;32m    237\u001b[0m )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData loaders created successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\micro_sam\\training\\training.py:547\u001b[0m, in \u001b[0;36mdefault_sam_loader\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m extra_ds_kwargs, loader_kwargs \u001b[38;5;241m=\u001b[39m split_kwargs(torch_em\u001b[38;5;241m.\u001b[39mdefault_segmentation_dataset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kwargs)\n\u001b[0;32m    545\u001b[0m ds_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msam_ds_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_ds_kwargs}\n\u001b[1;32m--> 547\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_sam_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mds_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch_em\u001b[38;5;241m.\u001b[39msegmentation\u001b[38;5;241m.\u001b[39mget_data_loader(ds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloader_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\micro_sam\\training\\training.py:490\u001b[0m, in \u001b[0;36mdefault_sam_dataset\u001b[1;34m(raw_paths, raw_key, label_paths, label_key, patch_shape, with_segmentation_decoder, with_channels, sampler, raw_transform, n_samples, is_train, min_size, max_sampling_attempts, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# Set a minimum number of samples per epoch.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 490\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_em\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_segmentation_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_seg_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_seg_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loader), \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m    505\u001b[0m dataset \u001b[38;5;241m=\u001b[39m torch_em\u001b[38;5;241m.\u001b[39mdefault_segmentation_dataset(\n\u001b[0;32m    506\u001b[0m     raw_paths\u001b[38;5;241m=\u001b[39mraw_paths,\n\u001b[0;32m    507\u001b[0m     raw_key\u001b[38;5;241m=\u001b[39mraw_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    519\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\torch_em\\segmentation.py:266\u001b[0m, in \u001b[0;36mdefault_segmentation_loader\u001b[1;34m(raw_paths, raw_key, label_paths, label_key, batch_size, patch_shape, label_transform, label_transform2, raw_transform, transform, dtype, label_dtype, rois, n_samples, sampler, ndim, is_seg_dataset, with_channels, with_label_channels, verify_paths, with_padding, z_ext, **loader_kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_segmentation_loader\u001b[39m(\n\u001b[0;32m    205\u001b[0m     raw_paths: Union[List[Any], \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    206\u001b[0m     raw_key: Optional[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloader_kwargs,\n\u001b[0;32m    228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader:\n\u001b[0;32m    229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get data loader for training a segmentation network.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m    See `torch_em.data.SegmentationDataset` and `torch_em.data.ImageCollectionDataset` for details\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m        The torch data loader.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_segmentation_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_transform2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_transform2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_seg_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_seg_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_label_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_label_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_padding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz_ext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_ext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_data_loader(ds, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloader_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\torch_em\\segmentation.py:368\u001b[0m, in \u001b[0;36mdefault_segmentation_dataset\u001b[1;34m(raw_paths, raw_key, label_paths, label_key, patch_shape, label_transform, label_transform2, raw_transform, transform, dtype, label_dtype, rois, n_samples, sampler, ndim, is_seg_dataset, with_channels, with_label_channels, verify_paths, with_padding, z_ext)\u001b[0m\n\u001b[0;32m    363\u001b[0m     transform \u001b[38;5;241m=\u001b[39m _get_default_transform(\n\u001b[0;32m    364\u001b[0m         raw_paths \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_paths, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m raw_paths[\u001b[38;5;241m0\u001b[39m], raw_key, is_seg_dataset, ndim\n\u001b[0;32m    365\u001b[0m     )\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_seg_dataset:\n\u001b[1;32m--> 368\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43m_load_segmentation_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_transform2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_transform2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_label_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_label_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_padding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz_ext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_ext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     ds \u001b[38;5;241m=\u001b[39m _load_image_collection_dataset(\n\u001b[0;32m    392\u001b[0m         raw_paths,\n\u001b[0;32m    393\u001b[0m         raw_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m         with_padding\u001b[38;5;241m=\u001b[39mwith_padding,\n\u001b[0;32m    407\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\torch_em\\segmentation.py:109\u001b[0m, in \u001b[0;36m_load_segmentation_dataset\u001b[1;34m(raw_paths, raw_key, label_paths, label_key, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rois, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(roi, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m roi \u001b[38;5;129;01min\u001b[39;00m rois)\n\u001b[1;32m--> 109\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mSegmentationDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(raw_paths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\torch_em\\data\\segmentation_dataset.py:103\u001b[0m, in \u001b[0;36mSegmentationDataset.__init__\u001b[1;34m(self, raw_path, raw_key, label_path, label_key, patch_shape, raw_transform, label_transform, label_transform2, transform, roi, dtype, label_dtype, n_samples, sampler, ndim, with_channels, with_label_channels, with_padding, z_ext)\u001b[0m\n\u001b[0;32m    101\u001b[0m shape_raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_channels \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    102\u001b[0m shape_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_label_channels \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m shape_raw \u001b[38;5;241m==\u001b[39m shape_label, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape_raw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m shape_raw\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroi \u001b[38;5;241m=\u001b[39m roi\n",
      "\u001b[1;31mAssertionError\u001b[0m: (3, 1024, 1024), (3, 512, 512)"
     ]
    }
   ],
   "source": [
    "# ‚ú® Execute training with convenience function\n",
    "print(\"Starting micro-SAM training...\")\n",
    "\n",
    "training_results = run_training(training_config, framework=\"microsam\")\n",
    "\n",
    "print(f'üéâ Training completed successfully!')\n",
    "print(f'Training Results:')\n",
    "print(f'  Model name: {training_results[\"model_name\"]}')\n",
    "print(f'  Final model: {training_results.get(\"final_model_path\", \"Not available\")}')\n",
    "print(f'  Checkpoints saved: {len(training_results.get(\"checkpoints\", []))}')\n",
    "print(f'  Output directory: {training_results[\"output_dir\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Export and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best checkpoint\n",
    "checkpoints = list(checkpoint_folder.glob(\"*.pt\"))\n",
    "if checkpoints:\n",
    "    latest_checkpoint = sorted(checkpoints)[-1]\n",
    "    print(f\"Latest checkpoint: {latest_checkpoint}\")\n",
    "    \n",
    "    # Export model for inference\n",
    "    export_path = output_directory / f\"{model_name}_final.pt\"\n",
    "    print(f\"Model exported to: {export_path}\")\n",
    "else:\n",
    "    print(\"No checkpoints found.\")\n",
    "\n",
    "print(f\"\\nTraining summary:\")\n",
    "print(f\"  Output directory: {output_directory}\")\n",
    "print(f\"  Model name: {model_name}\")\n",
    "print(f\"  Training completed with {n_iterations} iterations\")\n",
    "print(f\"  Dataset statistics: {training_result['stats']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close OMERO connection\n",
    "if conn is not None:\n",
    "    conn.close()\n",
    "    print(\"OMERO connection closed.\")\n",
    "else:\n",
    "    print(\"No active OMERO connection to close.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
