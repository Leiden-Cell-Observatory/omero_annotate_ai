{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro-SAM Training from OMERO Data\n",
    "\n",
    "Train micro-SAM models using annotation tables from OMERO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package\n",
    "from omero_annotate_ai import (\n",
    "    create_omero_connection_widget,\n",
    "    create_training_data_widget\n",
    ")\n",
    "\n",
    "# Additional imports for training\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "print(f\"Available widgets: Connection, Training Data\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OMERO Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display OMERO connection widget\n",
    "conn_widget = create_omero_connection_widget()\n",
    "conn_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OMERO connection\n",
    "conn = conn_widget.get_connection()\n",
    "\n",
    "if conn is None:\n",
    "    raise ConnectionError(\"No OMERO connection established.\")\n",
    "\n",
    "print(f\"Connected to OMERO as: {conn.getUser().getName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data selection widget\n",
    "training_widget = create_training_data_widget(connection=conn)\n",
    "training_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected training table\n",
    "selected_table_id = training_widget.get_selected_table_id()\n",
    "selected_table_info = training_widget.get_selected_table_info()\n",
    "\n",
    "if selected_table_id:\n",
    "    print(f\"Selected training table:\")\n",
    "    print(f\"  Table ID: {selected_table_id}\")\n",
    "    print(f\"  Table Name: {selected_table_info.get('name', 'Unknown')}\")\n",
    "    print(f\"  Created: {selected_table_info.get('created', 'Unknown')}\")\n",
    "else:\n",
    "    raise ValueError(\"No training table selected. Please select a table above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Training Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for training\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "home_dir = Path.home()\n",
    "models_dir = home_dir / \"micro-sam_models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "folder_name = f\"micro-sam-{timestamp}\"\n",
    "output_directory = models_dir / folder_name\n",
    "output_directory.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Training output directory: {output_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preparation (Manual Implementation)\n",
    "\n",
    "This section contains the manual data preparation logic that will be replaced by the `prepare_training_data_from_table()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules for manual data preparation\n",
    "import ezomero\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the table data\n",
    "table = ezomero.get_table(conn, selected_table_id)\n",
    "print(f\"Table contains {len(table)} rows\")\n",
    "print(f\"Columns: {list(table.columns)}\")\n",
    "print(table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_from_table(conn, df, output_dir, subset_type=\"training\", tmp_dir=None):\n",
    "    \"\"\"\n",
    "    Prepare dataset from tracking table\n",
    "    \n",
    "    Args:\n",
    "        conn: OMERO connection\n",
    "        df: DataFrame with tracking info\n",
    "        output_dir: Base output directory\n",
    "        subset_type: \"training\" or \"val\"\n",
    "        tmp_dir: Temporary directory for downloading annotations\n",
    "        \n",
    "    Returns:\n",
    "        (input_dir, label_dir): Paths to the input and label directories\n",
    "    \"\"\"\n",
    "    if tmp_dir is None:\n",
    "        tmp_dir = output_dir / \"tmp\"\n",
    "        tmp_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    input_dir = output_dir / f\"{subset_type}_input\"\n",
    "    label_dir = output_dir / f\"{subset_type}_label\"\n",
    "    input_dir.mkdir(exist_ok=True)\n",
    "    label_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for n in tqdm(range(len(df)), desc=f\"Preparing {subset_type} data\"):\n",
    "        try:\n",
    "            # Extract metadata\n",
    "            image_id = int(df.iloc[n]['image_id'])\n",
    "            \n",
    "            # Handle z_slice\n",
    "            z_slice = df.iloc[n]['z_slice']\n",
    "            if pd.isna(z_slice):\n",
    "                z_slice = 0\n",
    "            elif isinstance(z_slice, str) and z_slice.startswith('['):\n",
    "                try:\n",
    "                    z_slice = eval(z_slice)\n",
    "                    if isinstance(z_slice, list) and len(z_slice) > 0:\n",
    "                        z_slice = z_slice[0]\n",
    "                except:\n",
    "                    z_slice = 0\n",
    "            \n",
    "            # Handle other metadata\n",
    "            channel = int(df.iloc[n]['channel']) if pd.notna(df.iloc[n]['channel']) else 0\n",
    "            timepoint = int(df.iloc[n]['timepoint']) if pd.notna(df.iloc[n]['timepoint']) else 0\n",
    "            \n",
    "            # Get patch information\n",
    "            is_patch = bool(df.iloc[n]['is_patch']) if 'is_patch' in df.columns and pd.notna(df.iloc[n]['is_patch']) else False\n",
    "            patch_x = int(df.iloc[n]['patch_x']) if pd.notna(df.iloc[n]['patch_x']) else 0\n",
    "            patch_y = int(df.iloc[n]['patch_y']) if pd.notna(df.iloc[n]['patch_y']) else 0\n",
    "            patch_width = int(df.iloc[n]['patch_width']) if pd.notna(df.iloc[n]['patch_width']) else 0\n",
    "            patch_height = int(df.iloc[n]['patch_height']) if pd.notna(df.iloc[n]['patch_height']) else 0\n",
    "            \n",
    "            # Get image data\n",
    "            if is_patch and patch_width > 0 and patch_height > 0:\n",
    "                _, img_data = ezomero.get_image(\n",
    "                    conn,\n",
    "                    image_id,\n",
    "                    start_coords=(patch_x, patch_y, int(z_slice), channel, timepoint),\n",
    "                    axis_lengths=(patch_width, patch_height, 1, 1, 1),\n",
    "                    xyzct=True\n",
    "                )\n",
    "            else:\n",
    "                _, img_data = ezomero.get_image(\n",
    "                    conn,\n",
    "                    image_id,\n",
    "                    start_coords=(0, 0, int(z_slice), channel, timepoint),\n",
    "                    axis_lengths=(None, None, 1, 1, 1),\n",
    "                    xyzct=True\n",
    "                )\n",
    "            \n",
    "            # Process image data\n",
    "            if len(img_data.shape) == 5:\n",
    "                img_data = img_data[:, :, 0, 0, 0]\n",
    "                img_data = np.swapaxes(img_data, 0, 1)\n",
    "            \n",
    "            # Normalize to 8-bit\n",
    "            max_val = img_data.max()\n",
    "            if max_val > 0:\n",
    "                img_8bit = ((img_data) * (255.0 / max_val)).astype(np.uint8)\n",
    "            else:\n",
    "                img_8bit = img_data.astype(np.uint8)\n",
    "            \n",
    "            # Save image\n",
    "            output_path = input_dir / f\"input_{n:05d}.tif\"\n",
    "            imwrite(output_path, img_8bit)\n",
    "            \n",
    "            # Get label file\n",
    "            label_id = int(df.iloc[n]['label_id']) if pd.notna(df.iloc[n]['label_id']) else None\n",
    "            if label_id:\n",
    "                try:\n",
    "                    file_path = ezomero.get_file_annotation(conn, label_id, str(tmp_dir))\n",
    "                    if file_path:\n",
    "                        label_dest = label_dir / f\"label_{n:05d}.tif\"\n",
    "                        shutil.move(file_path, label_dest)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error downloading label file: {e}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {subset_type} item {n}: {e}\")\n",
    "    \n",
    "    return input_dir, label_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up existing folders\n",
    "folders = [\"training_input\", \"training_label\", \"val_input\", \"val_label\", \"tmp\"]\n",
    "for folder in folders:\n",
    "    folder_path = output_directory / folder\n",
    "    if folder_path.exists():\n",
    "        shutil.rmtree(folder_path)\n",
    "\n",
    "# Prepare training and validation data\n",
    "train_images = table[table['train'] == True]\n",
    "val_images = table[table['validate'] == True]\n",
    "\n",
    "print(f\"Found {len(train_images)} training images and {len(val_images)} validation images\")\n",
    "\n",
    "# Process training data\n",
    "training_input_dir, training_label_dir = prepare_dataset_from_table(\n",
    "    conn, train_images, output_directory, subset_type=\"training\"\n",
    ")\n",
    "\n",
    "# Process validation data\n",
    "val_input_dir, val_label_dir = prepare_dataset_from_table(\n",
    "    conn, val_images, output_directory, subset_type=\"val\"\n",
    ")\n",
    "\n",
    "print(f\"Training data prepared in: {output_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import micro_sam.training as sam_training\n",
    "from torch_em.data import MinInstanceSampler\n",
    "from torch_em.util.debug import check_loader\n",
    "\n",
    "def determine_patch_shape_from_table(table_df, default_shape=(1, 512, 512), min_size=256):\n",
    "    \"\"\"Extract optimal patch shape from OMERO table\"\"\"\n",
    "    try:\n",
    "        if ('patch_width' in table_df.columns and 'patch_height' in table_df.columns and \n",
    "            not table_df['patch_width'].isna().all() and not table_df['patch_height'].isna().all()):\n",
    "            \n",
    "            patch_width = int(table_df['patch_width'].median())\n",
    "            patch_height = int(table_df['patch_height'].median())\n",
    "            \n",
    "            if patch_width > 0 and patch_height > 0:\n",
    "                patch_width = max(min_size, patch_width)\n",
    "                patch_height = max(min_size, patch_height)\n",
    "                \n",
    "                # Ensure even dimensions\n",
    "                patch_width = patch_width - (patch_width % 2)\n",
    "                patch_height = patch_height - (patch_height % 2)\n",
    "                \n",
    "                new_shape = (1, patch_height, patch_width)\n",
    "                print(f\"Using patch shape {new_shape} from table\")\n",
    "                return new_shape\n",
    "        \n",
    "        print(f\"Using default patch shape {default_shape}\")\n",
    "        return default_shape\n",
    "    except Exception as e:\n",
    "        print(f\"Error determining patch shape: {e}, using default {default_shape}\")\n",
    "        return default_shape\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 2\n",
    "patch_shape = determine_patch_shape_from_table(table)\n",
    "train_instance_segmentation = True\n",
    "sampler = MinInstanceSampler(min_size=25)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = sam_training.default_sam_loader(\n",
    "    raw_paths=str(training_input_dir),\n",
    "    raw_key=\"*.tif\",\n",
    "    label_paths=str(training_label_dir),\n",
    "    label_key=\"*.tif\",\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    patch_shape=patch_shape,\n",
    "    batch_size=batch_size,\n",
    "    is_seg_dataset=True,\n",
    "    shuffle=True,\n",
    "    raw_transform=sam_training.identity,\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "val_loader = sam_training.default_sam_loader(\n",
    "    raw_paths=str(val_input_dir),\n",
    "    raw_key=\"*.tif\",\n",
    "    label_paths=str(val_label_dir),\n",
    "    label_key=\"*.tif\",\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    patch_shape=patch_shape,\n",
    "    batch_size=batch_size,\n",
    "    is_seg_dataset=True,\n",
    "    shuffle=True,\n",
    "    raw_transform=sam_training.identity,\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "# Check data loaders\n",
    "check_loader(train_loader, 1, plt=True)\n",
    "check_loader(val_loader, 1, plt=True)\n",
    "\n",
    "print(f\"Data loaders created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_objects_per_batch = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_epochs = 100\n",
    "model_type = \"vit_b_lm\"\n",
    "checkpoint_name = \"sam\"\n",
    "\n",
    "print(f\"Training on: {device}\")\n",
    "print(f\"Model type: {model_type}\")\n",
    "print(f\"Epochs: {n_epochs}\")\n",
    "\n",
    "# Run training\n",
    "sam_training.train_sam(\n",
    "    name=checkpoint_name,\n",
    "    save_root=str(output_directory / \"models\"),\n",
    "    model_type=model_type,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=n_epochs,\n",
    "    n_objects_per_batch=n_objects_per_batch,\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f\"Training completed. Model saved to: {output_directory / 'models'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micro_sam.bioimageio.model_export import export_sam_model\n",
    "\n",
    "# Get test images for export\n",
    "test_image_path = val_input_dir / list(val_input_dir.glob(\"*.tif\"))[0].name\n",
    "test_label_path = val_label_dir / list(val_label_dir.glob(\"*.tif\"))[0].name\n",
    "\n",
    "# Load test data\n",
    "test_image = np.array(imread(test_image_path))\n",
    "test_label = np.array(imread(test_label_path))\n",
    "\n",
    "# Export to bioimage.io format\n",
    "bioimageio_model_path = output_directory / \"bioimage_io_model\"\n",
    "bioimageio_model_path.mkdir(exist_ok=True)\n",
    "\n",
    "export_sam_model(\n",
    "    image=test_image,\n",
    "    label_image=test_label,\n",
    "    model_type=model_type,\n",
    "    name=f\"micro_sam_{timestamp}\",\n",
    "    output_path=str(bioimageio_model_path),\n",
    "    checkpoint_path=str(output_directory / \"models\" / \"checkpoints\" / checkpoint_name / \"best.pt\"),\n",
    "    authors=[{\"name\": \"User\", \"affiliation\": \"Institution\"}],\n",
    "    description=\"Micro-SAM model trained on OMERO data\",\n",
    "    license=\"MIT\",\n",
    "    documentation=\"Model trained with micro-sam\",\n",
    ")\n",
    "\n",
    "print(f\"Model exported to: {bioimageio_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close OMERO connection\n",
    "if conn:\n",
    "    conn.close()\n",
    "    print(\"OMERO connection closed\")\n",
    "\n",
    "print(f\"Training completed successfully!\")\n",
    "print(f\"Output directory: {output_directory}\")\n",
    "print(f\"Trained model: {output_directory / 'models' / 'checkpoints' / checkpoint_name / 'best.pt'}\")\n",
    "print(f\"BioImage.IO model: {bioimageio_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}