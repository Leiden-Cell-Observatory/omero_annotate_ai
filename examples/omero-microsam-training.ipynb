{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omero.gateway import BlitzGateway\n",
    "import ezomero\n",
    "#load dotenv for OMERO login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from tifffile import imsave, imwrite, imread\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "from torch_em.util.debug import check_loader\n",
    "from torch_em.data import MinInstanceSampler\n",
    "from torch_em.util.util import get_random_colors\n",
    "\n",
    "import micro_sam.training as sam_training\n",
    "from micro_sam.sample_data import fetch_tracking_example_data, fetch_tracking_segmentation_data\n",
    "from micro_sam.automatic_segmentation import get_predictor_and_segmenter, automatic_instance_segmentation\n",
    "\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Reload all src submodules\n",
    "src_modules = [\n",
    "    \"src.omero_functions\",\n",
    "    \"src.file_io_functions\",\n",
    "    \"src.image_functions\",\n",
    "    \"src.utils\",\n",
    "    \"src.processing_pipeline\",\n",
    "]\n",
    "\n",
    "\n",
    "def reload_module(module_name):\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "    return __import__(module_name)\n",
    "\n",
    "\n",
    "for module in src_modules:\n",
    "    reload_module(module)\n",
    "\n",
    "# Re-import after reloading to ensure we have the latest versions\n",
    "from src.omero_functions import (\n",
    "    print_object_details,\n",
    "    get_images_from_container,\n",
    "    get_dask_image,\n",
    "    upload_rois_and_labels,\n",
    "    initialize_tracking_table,\n",
    "    update_tracking_table_rows,\n",
    "    get_dask_image_multiple,\n",
    "    get_dask_dimensions,\n",
    ")\n",
    "from src.file_io_functions import (\n",
    "    zip_directory,\n",
    "    store_annotations_in_zarr,\n",
    "    zarr_to_tiff,\n",
    "    cleanup_local_embeddings,\n",
    "    organize_local_outputs,\n",
    "    save_annotations_schema,\n",
    ")\n",
    "from src.image_functions import label_to_rois, generate_patch_coordinates, extract_patch\n",
    "from src.utils import NumpyEncoder, interleave_arrays\n",
    "from src.processing_pipeline import process_omero_batch\n",
    "\n",
    "from napari.settings import get_settings\n",
    "\n",
    "get_settings().application.ipy_interactive = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup connection with OMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "# Ask for password if not set\n",
    "if not os.environ.get(\"PASSWORD\"):\n",
    "    from getpass import getpass\n",
    "\n",
    "    os.environ[\"PASSWORD\"] = getpass(\"Enter OMERO server password: \")\n",
    "\n",
    "conn = BlitzGateway(\n",
    "    host=os.environ.get(\"HOST\"),\n",
    "    username=os.environ.get(\"USER_NAME\"),\n",
    "    passwd=os.environ.get(\"PASSWORD\"),\n",
    "    group=os.environ.get(\"GROUP\"),\n",
    "    secure=True,\n",
    ")\n",
    "\n",
    "connection_status = conn.connect()\n",
    "if connection_status:\n",
    "    print(\"Connected to OMERO Server\")\n",
    "else:\n",
    "    print(\"Connection to OMERO Server Failed\")\n",
    "conn.c.enableKeepAlive(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"dataset\" # \"screen\", \"plate\", \"project\", \"dataset\", \"image\"\n",
    "data_id = 351\n",
    "trainingset_name = \"micro_sam_training_data_20240605\"\n",
    "\n",
    "\n",
    "# Validate that data_id matches datatype and print details\n",
    "if datatype == \"project\":\n",
    "    project = conn.getObject(\"Project\", data_id)\n",
    "    if project is None:\n",
    "        raise ValueError(f\"Project with ID {data_id} not found\")\n",
    "    print_object_details(conn, project, \"project\")\n",
    "\n",
    "elif datatype == \"plate\":\n",
    "    plate = conn.getObject(\"Plate\", data_id)\n",
    "    if plate is None:\n",
    "        raise ValueError(f\"Plate with ID {data_id} not found\")\n",
    "    print_object_details(conn, plate, \"plate\")\n",
    "\n",
    "elif datatype == \"dataset\":\n",
    "    dataset = conn.getObject(\"Dataset\", data_id)\n",
    "    if dataset is None:\n",
    "        raise ValueError(f\"Dataset with ID {data_id} not found\")\n",
    "    print_object_details(conn, dataset, \"dataset\")\n",
    "\n",
    "elif datatype == \"image\":\n",
    "    image = conn.getObject(\"Image\", data_id)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image with ID {data_id} not found\")\n",
    "    print_object_details(conn, image, \"image\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid datatype specified\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output folders for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "models_dir = os.path.join(home_dir, \"micro-sam_models\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "folder_name = f\"micro-sam-{timestamp}\"\n",
    "output_directory = os.path.join(models_dir, folder_name)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "output_directory = os.path.abspath(output_directory)\n",
    "#output_directory = os.path.abspath(\"C:\\\\Users\\\\mwpaul\\\\micro-sam_models\\\\micro-sam-20250207_095503\")\n",
    "print(f\"Output directory: {output_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting data from OMERO using the attached table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_specific_table(conn, datatype, dataset_id, table_name=\"micro_sam_training_data\"):\n",
    "    \"\"\"\n",
    "    Find and return a specific table attached to a dataset by its name.\n",
    "    \n",
    "    Args:\n",
    "        conn: OMERO connection\n",
    "        datatype: Type of the dataset (e.g., \"project\", \"dataset\")\n",
    "        dataset_id: ID of the dataset to search\n",
    "        table_name: Name of the table file to find\n",
    "        \n",
    "    Returns:\n",
    "        table: Table data as pandas DataFrame or list of lists\n",
    "        file_ann_id: ID of the file annotation containing the table\n",
    "    \"\"\"\n",
    "    # Get all file annotations on the dataset\n",
    "    file_ann_ids = ezomero.get_file_annotation_ids(conn, datatype, dataset_id)\n",
    "    \n",
    "    # Get original file details to check names\n",
    "    for ann_id in file_ann_ids:\n",
    "        ann = conn.getObject(\"FileAnnotation\", ann_id)\n",
    "        if ann is None:\n",
    "            continue\n",
    "            \n",
    "        orig_file = ann.getFile()\n",
    "        if orig_file.getName() == table_name:\n",
    "            try:\n",
    "                table = ezomero.get_table(conn, ann_id)\n",
    "                return table, ann_id\n",
    "            except Exception as e:\n",
    "                print(f\"Found file {table_name} but failed to load as table: {e}\")\n",
    "                continue\n",
    "                \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table, file_ann_id = get_specific_table(conn, datatype, data_id, trainingset_name)\n",
    "if table is not None:\n",
    "    print(f\"Found table {trainingset_name} in file annotation {file_ann_id}\")\n",
    "    # If pandas DataFrame:\n",
    "    print(table.head())\n",
    "else:\n",
    "    print(f\"No table named {trainingset_name} found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a reusable function to prepare training/validation data from OMERO table\n",
    "def prepare_dataset_from_table(conn, df, output_dir, subset_type=\"training\", tmp_dir=None):\n",
    "    \"\"\"\n",
    "    Prepare dataset from tracking table\n",
    "    \n",
    "    Args:\n",
    "        conn: OMERO connection\n",
    "        df: DataFrame with tracking info\n",
    "        output_dir: Base output directory\n",
    "        subset_type: \"training\" or \"val\"\n",
    "        tmp_dir: Temporary directory for downloading annotations\n",
    "        \n",
    "    Returns:\n",
    "        (input_dir, label_dir): Paths to the input and label directories\n",
    "    \"\"\"\n",
    "    if tmp_dir is None:\n",
    "        tmp_dir = os.path.join(output_dir, \"tmp\")\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "        \n",
    "    input_dir = os.path.join(output_dir, f\"{subset_type}_input\")\n",
    "    label_dir = os.path.join(output_dir, f\"{subset_type}_label\")\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "        progress_fn = tqdm\n",
    "    except ImportError:\n",
    "        # Simple progress function if tqdm is not available\n",
    "        def progress_fn(x, **kwargs):\n",
    "            return x\n",
    "    \n",
    "    for n in progress_fn(range(len(df)), desc=f\"Preparing {subset_type} data\"):\n",
    "        try:\n",
    "            # Extract metadata\n",
    "            image_id = int(df.iloc[n]['image_id'])\n",
    "            \n",
    "            # Handle z_slice - could be int, string representation of list, or NaN\n",
    "            z_slice = df.iloc[n]['z_slice']\n",
    "            if pd.isna(z_slice):\n",
    "                z_slice = 0\n",
    "            elif isinstance(z_slice, str) and z_slice.startswith('['):\n",
    "                try:\n",
    "                    z_slice = eval(z_slice)\n",
    "                    if isinstance(z_slice, list) and len(z_slice) > 0:\n",
    "                        z_slice = z_slice[0]  # Use first slice for 2D\n",
    "                except:\n",
    "                    z_slice = 0\n",
    "            \n",
    "            # Handle other metadata columns\n",
    "            channel = int(df.iloc[n]['channel']) if pd.notna(df.iloc[n]['channel']) else 0\n",
    "            timepoint = int(df.iloc[n]['timepoint']) if pd.notna(df.iloc[n]['timepoint']) else 0\n",
    "            is_volumetric = bool(df.iloc[n]['is_volumetric']) if 'is_volumetric' in df.columns and pd.notna(df.iloc[n]['is_volumetric']) else False\n",
    "            \n",
    "            # Get patch information\n",
    "            is_patch = bool(df.iloc[n]['is_patch']) if 'is_patch' in df.columns and pd.notna(df.iloc[n]['is_patch']) else False\n",
    "            patch_x = int(df.iloc[n]['patch_x']) if pd.notna(df.iloc[n]['patch_x']) else 0\n",
    "            patch_y = int(df.iloc[n]['patch_y']) if pd.notna(df.iloc[n]['patch_y']) else 0\n",
    "            patch_width = int(df.iloc[n]['patch_width']) if pd.notna(df.iloc[n]['patch_width']) else 0\n",
    "            patch_height = int(df.iloc[n]['patch_height']) if pd.notna(df.iloc[n]['patch_height']) else 0\n",
    "            \n",
    "            # Debug patch dimensions\n",
    "            print(f\"Item {n} - Image ID: {image_id}, Patch: {is_patch}, Dimensions: {patch_width}x{patch_height} at ({patch_x},{patch_y})\")\n",
    "            \n",
    "            # Process based on whether it's 3D volumetric or 2D\n",
    "            if is_volumetric:\n",
    "                # Handle 3D volumetric data\n",
    "                # Determine which z-slices to load\n",
    "                if isinstance(z_slice, list):\n",
    "                    z_slices = z_slice\n",
    "                elif z_slice == 'all':\n",
    "                    # Get image object to determine size\n",
    "                    omero_image, _ = ezomero.get_image(conn, image_id, no_pixels=True)\n",
    "                    if not omero_image:\n",
    "                        print(f\"Warning: Image {image_id} not found, skipping\")\n",
    "                        continue\n",
    "                    z_slices = range(omero_image.getSizeZ())\n",
    "                else:\n",
    "                    z_slices = [int(z_slice)]\n",
    "                \n",
    "                # Create empty 3D array to hold all z-slices\n",
    "                img_3d = []\n",
    "                \n",
    "                # Load each z-slice using ezomero.get_image\n",
    "                for z in z_slices:\n",
    "                    z_val = int(z)\n",
    "                    if is_patch and patch_width > 0 and patch_height > 0:\n",
    "                        # Debug start_coords and axis_lengths\n",
    "                        print(f\"  3D Patch Request - start_coords: ({patch_x}, {patch_y}, {z_val}, {channel}, {timepoint}), dimensions: {patch_width}x{patch_height}\")\n",
    "                        \n",
    "                        # Use ezomero.get_image to extract the patch for this z-slice\n",
    "                        _, img_slice = ezomero.get_image(\n",
    "                            conn,\n",
    "                            image_id,\n",
    "                            start_coords=(patch_x, patch_y, z_val, channel, timepoint),\n",
    "                            axis_lengths=(patch_width, patch_height, 1, 1, 1),\n",
    "                            xyzct=True  # Use XYZCT ordering\n",
    "                        )\n",
    "                        \n",
    "                        # Check shape of returned array\n",
    "                        print(f\"  Returned array shape (before extraction): {img_slice.shape}\")\n",
    "                        \n",
    "                        # The result will be 5D, extract just the 2D slice\n",
    "                        img_slice = img_slice[:,:,:, 0, 0]  # Extract the single z-slice\n",
    "                        print(f\"  Extracted slice shape: {img_slice.shape}\")\n",
    "                    else:\n",
    "                        # Get full plane for this z-slice\n",
    "                        _, img_slice = ezomero.get_image(\n",
    "                            conn,\n",
    "                            image_id,\n",
    "                            start_coords=(0, 0, z_val, channel, timepoint),\n",
    "                            axis_lengths=(None, None, 1, 1, 1),\n",
    "                            xyzct=True  # Use XYZCT ordering\n",
    "                        )\n",
    "                        # Check shape of returned array\n",
    "                        print(f\"  Full plane shape (before extraction): {img_slice.shape}\")\n",
    "                        \n",
    "                        # The result will be 5D, extract just the 2D slice\n",
    "                        img_slice = img_slice[0, 0, 0]  # Extract the single z-slice\n",
    "                        print(f\"  Extracted full plane shape: {img_slice.shape}\")\n",
    "                    \n",
    "                    img_3d.append(img_slice)\n",
    "                \n",
    "                # Convert to numpy array\n",
    "                img_3d = np.array(img_3d)\n",
    "                print(f\"  Final 3D array shape: {img_3d.shape}\")\n",
    "                \n",
    "                # Normalize 16-bit to 8-bit\n",
    "                max_val = img_3d.max()\n",
    "                if max_val > 0:\n",
    "                    img_8bit = ((img_3d) * (255.0 / max_val)).astype(np.uint8)\n",
    "                else:\n",
    "                    img_8bit = img_3d.astype(np.uint8)\n",
    "                \n",
    "                # Save as multi-page TIFF for 3D data\n",
    "                output_path = os.path.join(input_dir, f\"input_{n:05d}.tif\")\n",
    "                imwrite(output_path, img_8bit)\n",
    "                print(f\"  Saved 3D TIFF to {output_path} with shape {img_8bit.shape}\")\n",
    "                \n",
    "            else:\n",
    "                # Handle 2D data with patch support using ezomero.get_image\n",
    "                if is_patch and patch_width > 0 and patch_height > 0:\n",
    "                    # Use ezomero.get_image with appropriate coordinates and dimensions\n",
    "                    z_val = z_slice if not isinstance(z_slice, list) else z_slice[0]\n",
    "                    \n",
    "                    # Debug start_coords and axis_lengths\n",
    "                    print(f\"  2D Patch Request - start_coords: ({patch_x}, {patch_y}, {z_val}, {channel}, {timepoint}), dimensions: {patch_width}x{patch_height}\")\n",
    "                    \n",
    "                    _, img_data = ezomero.get_image(\n",
    "                        conn,\n",
    "                        image_id,\n",
    "                        start_coords=(patch_x, patch_y, int(z_val), channel, timepoint),\n",
    "                        axis_lengths=(patch_width, patch_height, 1, 1, 1),\n",
    "                        xyzct=True\n",
    "                    )\n",
    "                    \n",
    "                    # Check shape of returned array\n",
    "                    print(f\"  Returned array shape: {img_data.shape}\")\n",
    "                    \n",
    "                    # The array is already in the right dimensions (width, height, z=1, c=1, t=1)\n",
    "                    # We just need to remove the trailing dimensions\n",
    "                    if len(img_data.shape) == 5:\n",
    "                        # Take only the first (and only) z, c, t indices\n",
    "                        img_data = img_data[:, :, 0, 0, 0]\n",
    "                        # swap x and y dimensions in the numpy array\n",
    "                        img_data = np.swapaxes(img_data, 0, 1)\n",
    "\n",
    "                    \n",
    "                    print(f\"  Extracted 2D shape: {img_data.shape}\")\n",
    "                else:\n",
    "                    # Get full plane\n",
    "                    z_val = z_slice if not isinstance(z_slice, list) else z_slice[0]\n",
    "                    \n",
    "                    # Debug start_coords\n",
    "                    print(f\"  2D Full Image Request - start_coords: (0, 0, {z_val}, {channel}, {timepoint})\")\n",
    "                    \n",
    "                    _, img_data = ezomero.get_image(\n",
    "                        conn,\n",
    "                        image_id,\n",
    "                        start_coords=(0, 0, int(z_val), channel, timepoint),\n",
    "                        axis_lengths=(None, None, 1, 1, 1),\n",
    "                        xyzct=True \n",
    "                    )\n",
    "                    \n",
    "                    # Check shape of returned array \n",
    "                    print(f\"  Returned array shape: {img_data.shape}\")\n",
    "                    \n",
    "                    # Remove trailing dimensions\n",
    "                    if len(img_data.shape) == 5:\n",
    "                        img_data = img_data[:, :, 0, 0, 0]\n",
    "                        img_data = np.swapaxes(img_data, 0, 1)\n",
    "                    \n",
    "                    print(f\"  Extracted 2D shape: {img_data.shape}\")\n",
    "                \n",
    "                # Normalize 16-bit to 8-bit\n",
    "                max_val = img_data.max()\n",
    "                if max_val > 0:\n",
    "                    img_8bit = ((img_data) * (255.0 / max_val)).astype(np.uint8)\n",
    "                else:\n",
    "                    img_8bit = img_data.astype(np.uint8)\n",
    "                \n",
    "                # Save as TIFF\n",
    "                output_path = os.path.join(input_dir, f\"input_{n:05d}.tif\")\n",
    "                imwrite(output_path, img_8bit)\n",
    "                print(f\"  Saved 2D TIFF to {output_path} with shape {img_8bit.shape}\")\n",
    "            \n",
    "            # Get the label file\n",
    "            label_id = int(df.iloc[n]['label_id']) if pd.notna(df.iloc[n]['label_id']) else None\n",
    "            if label_id:\n",
    "                try:\n",
    "                    file_path = ezomero.get_file_annotation(conn, label_id, tmp_dir)\n",
    "                    if file_path:\n",
    "                        label_dest = os.path.join(label_dir, f\"label_{n:05d}.tif\")\n",
    "                        os.rename(file_path, label_dest)\n",
    "                        # Check the size of the saved label\n",
    "                        label_img = imread(label_dest)\n",
    "                        print(f\"  Label shape: {label_img.shape} saved to {label_dest}\")\n",
    "                    else:\n",
    "                        print(f\"  Warning: Label file for image {image_id} not downloaded\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error downloading label file: {e}\")\n",
    "            else:\n",
    "                print(f\"  Warning: No label ID for image {image_id}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {subset_type} item {n}: {e}\")\n",
    "    \n",
    "    return input_dir, label_dir\n",
    "\n",
    "# Clean up existing folders\n",
    "folders = [\"training_input\", \"training_label\", \"val_input\", \"val_label\", \"tmp\"]\t\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(output_directory, folder)\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "\n",
    "# Create tmp directory\n",
    "tmp_dir = os.path.join(output_directory, \"tmp\")\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "# Prepare training and validation data\n",
    "train_images = table[table['train'] == True]\n",
    "val_images = table[table['validate'] == True]\n",
    "\n",
    "print(f\"Found {len(train_images)} training images and {len(val_images)} validation images\")\n",
    "\n",
    "# Process training data\n",
    "training_input_dir, training_label_dir = prepare_dataset_from_table(\n",
    "    conn, \n",
    "    train_images, \n",
    "    output_directory, \n",
    "    subset_type=\"training\",\n",
    "    tmp_dir=tmp_dir\n",
    ")\n",
    "\n",
    "# Process validation data\n",
    "val_input_dir, val_label_dir = prepare_dataset_from_table(\n",
    "    conn, \n",
    "    val_images, \n",
    "    output_directory, \n",
    "    subset_type=\"val\",\n",
    "    tmp_dir=tmp_dir\n",
    ")\n",
    "\n",
    "print(\"Training data successfully saved to:\", output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data loader for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_patch_shape_from_table(table_df, default_shape=(1, 512, 512), min_size=256):\n",
    "    \"\"\"\n",
    "    Extract optimal patch shape from the OMERO table that contains patch dimensions\n",
    "    \n",
    "    Args:\n",
    "        table_df: DataFrame from OMERO table with patch information\n",
    "        default_shape: Default patch shape to use if no info available (default: (1, 512, 512))\n",
    "        min_size: Minimum acceptable patch dimension (default: 256)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Appropriate patch shape for training (C, H, W)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if we have patch dimensions in the table\n",
    "        if ('patch_width' in table_df.columns and 'patch_height' in table_df.columns and \n",
    "            not table_df['patch_width'].isna().all() and not table_df['patch_height'].isna().all()):\n",
    "            \n",
    "            # Get median patch dimensions from the table (to handle potential variation)\n",
    "            patch_width = int(table_df['patch_width'].median())\n",
    "            patch_height = int(table_df['patch_height'].median())\n",
    "            \n",
    "            # Validate dimensions (must be positive numbers)\n",
    "            if patch_width > 0 and patch_height > 0:\n",
    "                # Apply minimum size constraint\n",
    "                patch_width = max(min_size, patch_width)\n",
    "                patch_height = max(min_size, patch_height)\n",
    "                \n",
    "                # Ensure even dimensions for better compatibility\n",
    "                patch_width = patch_width - (patch_width % 2)\n",
    "                patch_height = patch_height - (patch_height % 2)\n",
    "                \n",
    "                new_shape = (1, patch_height, patch_width)\n",
    "                print(f\"Using patch shape {new_shape} extracted from OMERO table\")\n",
    "                return new_shape\n",
    "            else:\n",
    "                print(f\"Invalid patch dimensions in table: {patch_width}x{patch_height}, using default {default_shape}\")\n",
    "                return default_shape\n",
    "        else:\n",
    "            print(f\"No patch dimensions found in table, using default {default_shape}\")\n",
    "            return default_shape\n",
    "    except Exception as e:\n",
    "        print(f\"Error determining patch shape from table: {e}, using default {default_shape}\")\n",
    "        return default_shape\n",
    "\n",
    "batch_size = 2  # training batch size\n",
    "\n",
    "# Determine patch shape from the OMERO table that contains our annotations\n",
    "patch_shape = determine_patch_shape_from_table(\n",
    "    table,\n",
    "    default_shape=(1, 512, 512),\n",
    "    min_size=256\n",
    ")\n",
    "print(f\"Selected patch shape for training: {patch_shape}\")\n",
    "\n",
    "# Load images from multiple files in folder via pattern (here: all tif files)\n",
    "raw_key, label_key = \"*.tif\", \"*.tif\"\n",
    "\n",
    "# Train an additional convolutional decoder for end-to-end automatic instance segmentation\n",
    "# NOTE 1: It's important to have densely annotated-labels while training the additional convolutional decoder.\n",
    "# NOTE 2: In case you do not have labeled images, we recommend using `micro-sam` annotator tools to annotate as many objects as possible per image for best performance.\n",
    "train_instance_segmentation = True\n",
    "\n",
    "# NOTE: The dataloader internally takes care of adding label transforms: i.e. used to convert the ground-truth\n",
    "# labels to the desired instances for finetuning Segment Anythhing, or, to learn the foreground and distances\n",
    "# to the object centers and object boundaries for automatic segmentation.\n",
    "\n",
    "# There are cases where our inputs are large and the labeled objects are not evenly distributed across the image.\n",
    "# For this we use samplers, which ensure that valid inputs are chosen subjected to the paired labels.\n",
    "# The sampler chosen below makes sure that the chosen inputs have atleast one foreground instance, and filters out small objects.\n",
    "sampler = MinInstanceSampler(min_size=25)  # NOTE: The choice of 'min_size' value is paired with the same value in 'min_size' filter in 'label_transform'.\n",
    "\n",
    "train_loader = sam_training.default_sam_loader(\n",
    "    raw_paths=training_input_dir,\n",
    "    raw_key=raw_key,\n",
    "    label_paths=training_label_dir,\n",
    "    label_key=label_key,\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    patch_shape=patch_shape,\n",
    "    batch_size=batch_size,\n",
    "    is_seg_dataset=True,\n",
    "    #rois=train_roi,\n",
    "    shuffle=True,\n",
    "    raw_transform=sam_training.identity,\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "val_loader = sam_training.default_sam_loader(\n",
    "    raw_paths=val_input_dir,\n",
    "    raw_key=raw_key,\n",
    "    label_paths=val_label_dir,\n",
    "    label_key=label_key,\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    patch_shape=patch_shape,\n",
    "    batch_size=batch_size,\n",
    "    is_seg_dataset=True,\n",
    "    #rois=val_roi,\n",
    "    shuffle=True,\n",
    "    raw_transform=sam_training.identity,\n",
    "    sampler=sampler,\n",
    ")\n",
    "check_loader(train_loader, 1, plt=True)\n",
    "check_loader(val_loader, 1, plt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_objects_per_batch = 2  # the number of objects per batch that will be sampled\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # the device/GPU used for training\n",
    "n_epochs = 100  # how long we train (in epochs)\n",
    "print('running on: ', device)\n",
    "# The model_type determines which base model is used to initialize the weights that are finetuned.\n",
    "# We use vit_b here because it can be trained faster. Note that vit_h usually yields higher quality results.\n",
    "model_type = \"vit_b_lm\"\n",
    "\n",
    "# The name of the checkpoint. The checkpoints will be stored in './checkpoints/<checkpoint_name>'\n",
    "checkpoint_name = \"sam\"\n",
    "\n",
    "sam_training.train_sam(\n",
    "    name=checkpoint_name,\n",
    "    save_root=os.path.join(output_directory, \"models\"),\n",
    "    model_type=model_type,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=n_epochs,\n",
    "    #checkpoint_path='C:\\\\Users\\\\mwpaul\\\\micro-sam_models\\\\micro-sam-20250207_095503\\\\models\\\\checkpoints\\\\sam\\\\best.pt', #can be used to train further\n",
    "    n_objects_per_batch=n_objects_per_batch,\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save as bioimage.io model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Union\n",
    "from micro_sam.bioimageio.model_export import export_sam_model\n",
    "\n",
    "# Get a test image and label to use for exporting\n",
    "# For this example, we'll use the first image and label from validation set\n",
    "test_image_path = os.path.join(val_input_dir, os.listdir(val_input_dir)[0])\n",
    "test_label_path = os.path.join(val_label_dir, os.listdir(val_label_dir)[0])\n",
    "\n",
    "# Load the test image and label\n",
    "test_image = np.array(imread(test_image_path))\n",
    "test_label = np.array(imread(test_label_path))\n",
    "\n",
    "# Define the path for saving the bioimage.io model\n",
    "bioimageio_model_path = os.path.join(output_directory, \"bioimage_io_model\")\n",
    "os.makedirs(bioimageio_model_path, exist_ok=True)\n",
    "\n",
    "# Export the SAM model to bioimage.io format\n",
    "export_sam_model(\n",
    "    image=test_image,\n",
    "    label_image=test_label,\n",
    "    model_type=model_type,  # Using the same model_type as in training\n",
    "    name=f\"micro_sam_{timestamp}\",\n",
    "    output_path=bioimageio_model_path,\n",
    "    checkpoint_path=os.path.join(\n",
    "        output_directory, \"models\", \"checkpoints\", checkpoint_name, \"best.pt\"\n",
    "    ),\n",
    "    # Optional: Add additional kwargs as needed\n",
    "    authors=[{\"name\": \"Your Name\", \"affiliation\": \"Your Institution\"}],\n",
    "    description=\"Micro-SAM model trained on microscopy images for segmentation\",\n",
    "    license=\"MIT\",\n",
    "    documentation=\"Model trained with micro-sam for segmenting microscopy images\",\n",
    ")\n",
    "\n",
    "print(f\"BioImage.IO model exported to: {bioimageio_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
