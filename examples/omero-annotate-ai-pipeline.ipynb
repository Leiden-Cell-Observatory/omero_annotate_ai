{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMERO Micro-SAM Streamlined Workflow\n",
    "\n",
    "This notebook demonstrates the streamlined 2-widget workflow using the `omero-annotate-ai` package.\n",
    "\n",
    "## Key Features:\n",
    "- **2 Widget Workflow**: Only connection and workflow widgets needed\n",
    "- **Sequential Process**: Step-by-step guided workflow\n",
    "- **Complete Integration**: Direct pipeline execution with `run_full_workflow()`\n",
    "- **Secure Connection**: Built-in keychain support and connection management\n",
    "\n",
    "## Process Overview:\n",
    "1. **OMERO Connection** - Secure connection with password management\n",
    "2. **Workflow Setup** - Sequential configuration process\n",
    "3. **Pipeline Execution** - Run the complete annotation workflow\n",
    "4. **Results** - View results and export configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "**Prerequisites:**\n",
    "```bash\n",
    "# Activate micro-sam environment\n",
    "conda activate micro-sam\n",
    "\n",
    "# Install the package\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "**Note**: The micro-sam dependency must be installed separately:\n",
    "```bash\n",
    "conda install -c conda-forge micro-sam\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 omero-annotate-ai version: 0.1.0\n",
      "🔗 Available widgets: Connection, Workflow\n",
      "✨ Streamlined 2-widget workflow ready!\n",
      "🔗 OMERO functionality: ✅ Available\n",
      "🔑 Keyring support: ✅ Available\n"
     ]
    }
   ],
   "source": [
    "# Import the streamlined package\n",
    "import omero_annotate_ai\n",
    "from omero_annotate_ai import (\n",
    "    create_omero_connection_widget,\n",
    "    create_workflow_widget,\n",
    "    create_pipeline\n",
    ")\n",
    "\n",
    "# System imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"📦 omero-annotate-ai version: {omero_annotate_ai.__version__}\")\n",
    "print(f\"🔗 Available widgets: Connection, Workflow\")\n",
    "print(f\"✨ Streamlined 2-widget workflow ready!\")\n",
    "\n",
    "# Check dependencies\n",
    "try:\n",
    "    import ezomero\n",
    "    print(f\"🔗 OMERO functionality: ✅ Available\")\n",
    "except ImportError:\n",
    "    print(f\"🔗 OMERO functionality: ❌ Install with: pip install -e .[omero]\")\n",
    "\n",
    "try:\n",
    "    import keyring\n",
    "    print(f\"🔑 Keyring support: ✅ Available\")\n",
    "except ImportError:\n",
    "    print(f\"🔑 Keyring support: ⚠️ Not available (manual password entry only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OMERO Connection\n",
    "\n",
    "Use the secure connection widget to connect to your OMERO server. This widget provides:\n",
    "- Auto-loading from `.env` and `.ezomero` files\n",
    "- Secure password storage in OS keychain\n",
    "- Connection testing and validation\n",
    "- Password expiration options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔌 OMERO Connection Setup\n",
      "Use the widget below to connect to your OMERO server:\n",
      "  • Fill in server details (host, username, password)\n",
      "  • Test connection before proceeding\n",
      "  • Choose password storage duration if desired\n",
      "  • Click 'Save & Connect' to establish connection\n",
      "\n",
      "📄 Loaded configuration from connection history: root@localhost\n",
      "⚠️ Error loading password from keychain: No recommended backend was available. Install a recommended 3rd party backend package; or, install the keyrings.alt package if you want to use the non-recommended backends. See https://pypi.org/project/keyring for details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0541e1e8faf045bd934886937d6b37af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>🔌 OMERO Server Connection</h3>', layout=Layout(margin='0 0 20px 0')), HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Next Step: Run the cell below after connecting to OMERO\n"
     ]
    }
   ],
   "source": [
    "# Create and display the OMERO connection widget\n",
    "print(\"🔌 OMERO Connection Setup\")\n",
    "print(\"Use the widget below to connect to your OMERO server:\")\n",
    "print(\"  • Fill in server details (host, username, password)\")\n",
    "print(\"  • Test connection before proceeding\")\n",
    "print(\"  • Choose password storage duration if desired\")\n",
    "print(\"  • Click 'Save & Connect' to establish connection\")\n",
    "print()\n",
    "\n",
    "conn_widget = create_omero_connection_widget()\n",
    "conn_widget.display()\n",
    "\n",
    "print(\"\\n📝 Next Step: Run the cell below after connecting to OMERO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OMERO connection established!\n",
      "👤 User: root\n",
      "🏢 Group: system\n",
      "🔐 Secure: True\n",
      "🔗 Connection ready for workflow setup\n"
     ]
    }
   ],
   "source": [
    "# Get the OMERO connection\n",
    "conn = conn_widget.get_connection()\n",
    "\n",
    "if conn is None:\n",
    "    raise ConnectionError(\"❌ No OMERO connection established. Please use the widget above to connect.\")\n",
    "\n",
    "print(\"✅ OMERO connection established!\")\n",
    "print(f\"👤 User: {conn.getUser().getName()}\")\n",
    "print(f\"🏢 Group: {conn.getGroupFromContext().getName()}\")\n",
    "print(f\"🔐 Secure: {conn.isSecure()}\")\n",
    "print(f\"🔗 Connection ready for workflow setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Workflow Configuration\n",
    "\n",
    "The workflow widget provides a sequential, step-by-step process for configuring your annotation workflow:\n",
    "\n",
    "### Workflow Steps:\n",
    "1. **Select Working Directory** - Choose where to save annotations\n",
    "2. **Choose Container** - Select OMERO container (dataset, project, etc.)\n",
    "3. **Check Existing Tables** - Scan for existing annotation tables\n",
    "4. **Configure Parameters** - Set micro-SAM and processing parameters\n",
    "5. **Save Configuration** - Review and save your settings\n",
    "\n",
    "### Features:\n",
    "- Sequential workflow with progress tracking\n",
    "- Automatic table management and naming\n",
    "- Complete micro-SAM configuration\n",
    "- Configuration preview and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 OMERO Annotation Workflow Setup\n",
      "Follow the sequential workflow below:\n",
      "  1. Select working directory\n",
      "  2. Choose OMERO container\n",
      "  3. Check existing annotation tables\n",
      "  4. Configure micro-SAM parameters\n",
      "  5. Save configuration\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108329300aaa4848861989ecc1ea6d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>🔬 OMERO Annotation Workflow</h3>', layout=Layout(margin='0 0 20px 0')), IntProg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Next Step: Complete the workflow above, then run the cell below\n"
     ]
    }
   ],
   "source": [
    "# Create and display the workflow widget\n",
    "print(\"🔬 OMERO Annotation Workflow Setup\")\n",
    "print(\"Follow the sequential workflow below:\")\n",
    "print(\"  1. Select working directory\")\n",
    "print(\"  2. Choose OMERO container\")\n",
    "print(\"  3. Check existing annotation tables\")\n",
    "print(\"  4. Configure micro-SAM parameters\")\n",
    "print(\"  5. Save configuration\")\n",
    "print()\n",
    "\n",
    "workflow_widget = create_workflow_widget(connection=conn)\n",
    "workflow_widget.display()\n",
    "\n",
    "print(\"\\n📝 Next Step: Complete the workflow above, then run the cell below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Execution\n",
    "\n",
    "Once you've completed the workflow configuration, we can run the complete annotation pipeline. This will:\n",
    "1. Create or resume from annotation tracking table\n",
    "2. Process images using micro-SAM\n",
    "3. Launch napari for interactive annotation\n",
    "4. Upload results to OMERO (or save locally in read-only mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration is valid!\n",
      "\n",
      "📋 Configuration Summary:\n",
      "   📦 Container: project (ID: 101)\n",
      "   🎯 Training Set: microsam_senescence_20250722_134531\n",
      "   🔬 Model: vit_b_lm\n",
      "   📺 Channel: 0\n",
      "   📁 Output: /mnt/c/Users/Maarten/Documents/Github/omero_annotate_ai/examples/omero_annotations\n",
      "   🔄 Resume from Table: False\n",
      "   📖 Read-only Mode: False\n",
      "   🧩 Patches: 1 per image (256×256)\n",
      "\n",
      "📊 Processing scope: 1 training + 1 validation\n"
     ]
    }
   ],
   "source": [
    "# Get configuration from workflow widget\n",
    "config = workflow_widget.get_config()\n",
    "\n",
    "# Validate configuration\n",
    "try:\n",
    "    config.validate()\n",
    "    print(\"✅ Configuration is valid!\")\n",
    "except ValueError as e:\n",
    "    print(f\"❌ Configuration validation failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"\\n📋 Configuration Summary:\")\n",
    "print(f\"   📦 Container: {config.omero.container_type} (ID: {config.omero.container_id})\")\n",
    "print(f\"   🎯 Training Set: {config.training.trainingset_name}\")\n",
    "print(f\"   🔬 Model: {config.micro_sam.model_type}\")\n",
    "print(f\"   📺 Channel: {config.omero.channel}\")\n",
    "print(f\"   📁 Output: {config.batch_processing.output_folder}\")\n",
    "print(f\"   🔄 Resume from Table: {config.workflow.resume_from_table}\")\n",
    "print(f\"   📖 Read-only Mode: {config.workflow.read_only_mode}\")\n",
    "\n",
    "if config.patches.use_patches:\n",
    "    print(f\"   🧩 Patches: {config.patches.patches_per_image} per image ({config.patches.patch_size[0]}×{config.patches.patch_size[1]})\")\n",
    "\n",
    "if config.micro_sam.three_d:\n",
    "    print(f\"   🧊 3D processing: Enabled\")\n",
    "\n",
    "print(f\"\\n📊 Processing scope: {'All images' if config.training.segment_all else f'{config.training.train_n} training + {config.training.validate_n} validation'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Validating project with ID 101...\n",
      "✅ Found project: Senescence\n",
      "📁 Loading images from project 101\n",
      "📊 Found 6 images\n",
      "\n",
      "📊 Found 6 images to process\n",
      "\n",
      "🖼️ Sample images:\n",
      "   1. r01c06.tif (ID: 252)\n",
      "   2. r01c05.tif (ID: 255)\n",
      "   3. r01c02.tif (ID: 251)\n",
      "   4. r01c01.tif (ID: 256)\n",
      "   5. r01c04.tif (ID: 253)\n",
      "   ... and 1 more images\n",
      "\n",
      "✅ Ready to process 6 images!\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline and preview what will be processed\n",
    "pipeline = create_pipeline(config, conn)\n",
    "\n",
    "# Get container details\n",
    "container_type = config.omero.container_type\n",
    "container_id = config.omero.container_id\n",
    "\n",
    "print(f\"🔍 Validating {container_type} with ID {container_id}...\")\n",
    "\n",
    "# Validate container exists\n",
    "container = conn.getObject(container_type.capitalize(), container_id)\n",
    "if container is None:\n",
    "    raise ValueError(f\"{container_type.capitalize()} with ID {container_id} not found\")\n",
    "\n",
    "print(f\"✅ Found {container_type}: {container.getName()}\")\n",
    "if container.getDescription():\n",
    "    print(f\"📝 Description: {container.getDescription()}\")\n",
    "\n",
    "# Get list of images that will be processed\n",
    "try:\n",
    "    images_list = pipeline.get_images_from_container()\n",
    "    print(f\"\\n📊 Found {len(images_list)} images to process\")\n",
    "    \n",
    "    # Show sample images\n",
    "    print(\"\\n🖼️ Sample images:\")\n",
    "    for i, img in enumerate(images_list[:5]):\n",
    "        if hasattr(img, 'getName'):\n",
    "            print(f\"   {i+1}. {img.getName()} (ID: {img.getId()})\")\n",
    "        else:\n",
    "            img_obj = conn.getObject(\"Image\", img)\n",
    "            if img_obj:\n",
    "                print(f\"   {i+1}. {img_obj.getName()} (ID: {img})\")\n",
    "    \n",
    "    if len(images_list) > 5:\n",
    "        print(f\"   ... and {len(images_list) - 5} more images\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error getting images from container: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\n✅ Ready to process {len(images_list)} images!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting annotation pipeline...\n",
      "   📊 Processing 6 images\n",
      "   🔬 Using micro-SAM model: vit_b_lm\n",
      "   ⚡ Processing: All images in one batch\n",
      "   🎨 Napari will open for interactive annotation\n",
      "   📝 Close napari windows when annotation is complete\n",
      "\n",
      "🚀 Creating annotation table\n",
      "📁 Loading images from project 101\n",
      "📊 Found 6 images\n",
      "📊 Creating table for 6 images with model: vit_b_lm\n",
      "📋 Creating new tracking table: microsam_training_microsam_senescence_20250722_134531\n",
      "📋 ROI namespace: omero_annotate_ai.table.microsam_training_microsam_senescence_20250722_134531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/omero_annotate_ai/omero/omero_functions.py:109: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/omero_annotate_ai/omero/omero_functions.py:109: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/omero_annotate_ai/omero/omero_functions.py:109: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/omero_annotate_ai/omero/omero_functions.py:109: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/omero_annotate_ai/omero/omero_functions.py:109: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/omero_annotate_ai/omero/omero_functions.py:114: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna('None').infer_objects(copy=False).astype(str)\n",
      "/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/omero_annotate_ai/omero/omero_functions.py:114: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna('None').infer_objects(copy=False).astype(str)\n",
      "/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/omero_annotate_ai/omero/omero_functions.py:114: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna('None').infer_objects(copy=False).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Created tracking table 'microsam_training_microsam_senescence_20250722_134531' with 2 units\n",
      "   Container: project 101\n",
      "   Table ID: 1057\n",
      "object group 0\n",
      "Stored configuration as annotation ID: 1058\n",
      "object group 0\n",
      "📊 Workflow status updated: 0/2 (0.0%) - pending\n",
      "📋 Created annotation table with ID: 1057\n",
      "🚀 Starting annotation processing from table ID: 1057\n",
      "📋 Getting unprocessed units from table 1057\n",
      "📋 Found 2 unprocessed units\n",
      "📋 Found 2 processing units\n",
      "🔄 Processing batch 1/1\n",
      "📊 Loading 1 images using dask...\n",
      "💾 Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n",
      "✅ Successfully loaded 1 images\n",
      "📊 Loading 1 images using dask...\n",
      "💾 Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n",
      "✅ Successfully loaded 1 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precompute state for files: 100%|██████████| 2/2 [01:18<00:00, 39.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputation took 82.6767578125 seconds (= 01:23 minutes)\n",
      "The first image to annotate is image number 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QObject::moveToThread: Current thread (0x61c1c3d48da0) is not the object's thread (0x61c1cdfb3880).\n",
      "Cannot move to target thread (0x61c1c3d48da0)\n",
      "\n",
      "WARNING:vispy:QObject::moveToThread: Current thread (0x61c1c3d48da0) is not the object's thread (0x61c1cdfb3880).\n",
      "Cannot move to target thread (0x61c1c3d48da0)\n",
      "\n",
      "WARNING: Could not load the Qt platform plugin \"xcb\" in \"/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "WARNING:vispy:Could not load the Qt platform plugin \"xcb\" in \"/home/maarten/miniconda3/envs/micro-sam/lib/python3.12/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "WARNING: This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb, eglfs, minimal, minimalegl, offscreen, vnc, webgl.\n",
      "\n",
      "WARNING:vispy:This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb, eglfs, minimal, minimalegl, offscreen, vnc, webgl.\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Run the complete annotation pipeline\n",
    "print(\"🚀 Starting annotation pipeline...\")\n",
    "print(f\"   📊 Processing {len(images_list)} images\")\n",
    "print(f\"   🔬 Using micro-SAM model: {config.micro_sam.model_type}\")\n",
    "\n",
    "if config.batch_processing.batch_size == 0:\n",
    "    print(f\"   ⚡ Processing: All images in one batch\")\n",
    "else:\n",
    "    print(f\"   📦 Processing: Batches of {config.batch_processing.batch_size} images\")\n",
    "\n",
    "print(f\"   🎨 Napari will open for interactive annotation\")\n",
    "print(f\"   📝 Close napari windows when annotation is complete\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Run the complete workflow - this is the key call!\n",
    "    table_id, processed_images = pipeline.run_full_workflow()\n",
    "    \n",
    "    print(f\"\\n🎉 Annotation pipeline completed successfully!\")\n",
    "    print(f\"📊 Processed {len(processed_images)} images\")\n",
    "    print(f\"📋 Tracking table ID: {table_id}\")\n",
    "    \n",
    "    if config.workflow.read_only_mode:\n",
    "        print(f\"💾 Annotations saved locally to: {config.batch_processing.output_folder}\")\n",
    "    else:\n",
    "        print(f\"☁️ Annotations uploaded to OMERO\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during annotation pipeline: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results and Export\n",
    "\n",
    "Review the results and export your configuration for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results summary\n",
    "print(\"📊 Pipeline Results Summary:\")\n",
    "print(f\"   🎯 Training Set: {config.training.trainingset_name}\")\n",
    "print(f\"   📋 Tracking Table ID: {table_id}\")\n",
    "print(f\"   📊 Images Processed: {len(processed_images)}\")\n",
    "print(f\"   📦 Container: {config.omero.container_type} (ID: {config.omero.container_id})\")\n",
    "print(f\"   🔬 Model Used: {config.micro_sam.model_type}\")\n",
    "print(f\"   📁 Output Location: {config.batch_processing.output_folder}\")\n",
    "\n",
    "# Show processed images\n",
    "if processed_images:\n",
    "    print(f\"\\n🖼️ Processed Images:\")\n",
    "    for i, img_id in enumerate(processed_images[:10]):\n",
    "        img_obj = conn.getObject(\"Image\", img_id)\n",
    "        if img_obj:\n",
    "            print(f\"   {i+1}. {img_obj.getName()} (ID: {img_id})\")\n",
    "    \n",
    "    if len(processed_images) > 10:\n",
    "        print(f\"   ... and {len(processed_images) - 10} more images\")\n",
    "\n",
    "print(f\"\\n✅ Pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export configuration for future use\n",
    "config_filename = f\"annotation_config_{config.training.trainingset_name}.yaml\"\n",
    "config_path = Path(config.batch_processing.output_folder) / config_filename\n",
    "\n",
    "try:\n",
    "    config.save_yaml(config_path)\n",
    "    print(f\"💾 Configuration saved to: {config_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not save to output folder, saving to current directory\")\n",
    "    config.save_yaml(config_filename)\n",
    "    print(f\"💾 Configuration saved to: {config_filename}\")\n",
    "\n",
    "print(f\"\\n📋 Configuration Summary:\")\n",
    "print(config.get_workflow_summary())\n",
    "\n",
    "print(f\"\\n🔄 To reuse this configuration:\")\n",
    "print(f\"```python\")\n",
    "print(f\"from omero_annotate_ai import load_config\")\n",
    "print(f\"config = load_config('{config_filename}')\")\n",
    "print(f\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Close the OMERO connection when finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close OMERO connection\n",
    "if 'conn' in locals() and conn is not None:\n",
    "    conn.close()\n",
    "    print(\"🔌 OMERO connection closed\")\n",
    "\n",
    "print(f\"\\n🎉 Streamlined workflow completed!\")\n",
    "print(f\"📊 Total images processed: {len(processed_images) if 'processed_images' in locals() else 0}\")\n",
    "print(f\"💾 Configuration saved for future use\")\n",
    "print(f\"✨ Ready for next annotation workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### 🔄 Reusing Configurations\n",
    "Save time by reusing your configuration:\n",
    "```python\n",
    "from omero_annotate_ai import load_config, create_pipeline\n",
    "config = load_config('annotation_config_your_training_set.yaml')\n",
    "pipeline = create_pipeline(config, conn)\n",
    "```\n",
    "\n",
    "### 🧪 Advanced Usage\n",
    "- **Batch Processing**: Set `batch_size > 0` for large datasets\n",
    "- **3D Processing**: Enable `three_d` for volumetric data\n",
    "- **Patch Processing**: Use `use_patches` for large images\n",
    "- **Read-only Mode**: Use `read_only_mode` for testing\n",
    "\n",
    "### 📚 Documentation\n",
    "- **Package Documentation**: See `CLAUDE.md` for development guidelines\n",
    "- **API Reference**: Use `help(function_name)` for detailed documentation\n",
    "- **Examples**: Check the `examples/` folder for more use cases\n",
    "\n",
    "### 🛠️ Development\n",
    "- **Testing**: Use `make test` to run the test suite\n",
    "- **Linting**: Use `make lint` for code quality checks\n",
    "- **Documentation**: Use `make docs` to build documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
