{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMERO Micro-SAM Workflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 omero-annotate-ai version: 0.1.0\n",
      "🔗 Available widgets: Connection, Workflow\n",
      "✨ Streamlined 2-widget workflow ready!\n",
      "🔗 OMERO functionality: ✅ Available\n",
      "🔑 Keyring support: ✅ Available\n"
     ]
    }
   ],
   "source": [
    "# Import the streamlined package\n",
    "import omero_annotate_ai\n",
    "from omero_annotate_ai import (\n",
    "    create_omero_connection_widget,\n",
    "    create_workflow_widget,\n",
    "    create_pipeline\n",
    ")\n",
    "\n",
    "# System imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"📦 omero-annotate-ai version: {omero_annotate_ai.__version__}\")\n",
    "print(f\"🔗 Available widgets: Connection, Workflow\")\n",
    "print(f\"✨ Streamlined 2-widget workflow ready!\")\n",
    "\n",
    "# Check dependencies\n",
    "try:\n",
    "    import ezomero\n",
    "    print(f\"🔗 OMERO functionality: ✅ Available\")\n",
    "except ImportError:\n",
    "    print(f\"🔗 OMERO functionality: ❌ Install with: pip install -e .[omero]\")\n",
    "\n",
    "try:\n",
    "    import keyring\n",
    "    print(f\"🔑 Keyring support: ✅ Available\")\n",
    "except ImportError:\n",
    "    print(f\"🔑 Keyring support: ⚠️ Not available (manual password entry only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OMERO Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔌 OMERO Connection Setup\n",
      "Use the widget below to connect to your OMERO server:\n",
      "  • Fill in server details (host, username, password)\n",
      "  • Test connection before proceeding\n",
      "  • Choose password storage duration if desired\n",
      "  • Click 'Save & Connect' to establish connection\n",
      "\n",
      "📄 Loaded configuration from connection history: root@localhost\n",
      "🔐 Password loaded from keychain (no expiration)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140dbc70e0f34cecbe297eafacdd2974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>🔌 OMERO Server Connection</h3>', layout=Layout(margin='0 0 20px 0')), HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Next Step: Run the cell below after connecting to OMERO\n"
     ]
    }
   ],
   "source": [
    "# Create and display the OMERO connection widget\n",
    "print(\"🔌 OMERO Connection Setup\")\n",
    "print(\"Use the widget below to connect to your OMERO server:\")\n",
    "print(\"  • Fill in server details (host, username, password)\")\n",
    "print(\"  • Test connection before proceeding\")\n",
    "print(\"  • Choose password storage duration if desired\")\n",
    "print(\"  • Click 'Save & Connect' to establish connection\")\n",
    "print()\n",
    "\n",
    "conn_widget = create_omero_connection_widget()\n",
    "conn_widget.display()\n",
    "\n",
    "print(\"\\n📝 Next Step: Run the cell below after connecting to OMERO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OMERO connection established!\n",
      "👤 User: root\n",
      "🏢 Group: system\n",
      "🔐 Secure: True\n",
      "🔗 Connection ready for workflow setup\n"
     ]
    }
   ],
   "source": [
    "# Get the OMERO connection\n",
    "conn = conn_widget.get_connection()\n",
    "\n",
    "if conn is None:\n",
    "    raise ConnectionError(\"❌ No OMERO connection established. Please use the widget above to connect.\")\n",
    "\n",
    "print(\"✅ OMERO connection established!\")\n",
    "print(f\"👤 User: {conn.getUser().getName()}\")\n",
    "print(f\"🏢 Group: {conn.getGroupFromContext().getName()}\")\n",
    "print(f\"🔐 Secure: {conn.isSecure()}\")\n",
    "print(f\"🔗 Connection ready for workflow setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Workflow Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 OMERO Annotation Workflow Setup\n",
      "Follow the sequential workflow below:\n",
      "  1. Select working directory\n",
      "  2. Choose OMERO container\n",
      "  3. Check existing annotation tables\n",
      "  4. Configure micro-SAM parameters\n",
      "  5. Save configuration\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7367cfa2f6244a3c859c56e1a1193de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>🔬 OMERO Annotation Workflow</h3>', layout=Layout(margin='0 0 20px 0')), IntProg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Next Step: Complete the workflow above, then run the cell below\n"
     ]
    }
   ],
   "source": [
    "# Create and display the workflow widget\n",
    "print(\"🔬 OMERO Annotation Workflow Setup\")\n",
    "print(\"Follow the sequential workflow below:\")\n",
    "print(\"  1. Select working directory\")\n",
    "print(\"  2. Choose OMERO container\")\n",
    "print(\"  3. Check existing annotation tables\")\n",
    "print(\"  4. Configure micro-SAM parameters\")\n",
    "print(\"  5. Save configuration\")\n",
    "print()\n",
    "\n",
    "workflow_widget = create_workflow_widget(connection=conn)\n",
    "workflow_widget.display()\n",
    "\n",
    "print(\"\\n📝 Next Step: Complete the workflow above, then run the cell below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Configuration Summary:\n",
      "   📦 Container: project (ID: 201)\n",
      "   🎯 Training Set: micro_sam_foci_test_20250823_104024\n",
      "   🔬 Model: vit_b_lm\n",
      "   📺 Channel: [0]\n",
      "   📁 Output: c:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\examples\\omero_annotations_tmp\n",
      "   🔄 Resume from Table: False\n",
      "   📖 Read-only Mode: False\n",
      "\n",
      "📊 Processing scope: 2 training + 2 validation\n"
     ]
    }
   ],
   "source": [
    "# Get configuration from workflow widget\n",
    "config = workflow_widget.get_config()\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"\\n📋 Configuration Summary:\")\n",
    "print(f\"   📦 Container: {config.omero.container_type} (ID: {config.omero.container_id})\")\n",
    "print(f\"   🎯 Training Set: {config.name}\")\n",
    "print(f\"   🔬 Model: {config.ai_model.model_type}\")\n",
    "print(f\"   📺 Channel: {config.spatial_coverage.channels}\")\n",
    "print(f\"   📁 Output: {config.output.output_directory}\")\n",
    "print(f\"   🔄 Resume from Table: {config.workflow.resume_from_table}\")\n",
    "print(f\"   📖 Read-only Mode: {config.workflow.read_only_mode}\")\n",
    "\n",
    "if config.processing.use_patches:\n",
    "    print(f\"   🧩 Patches: {config.processing.patches_per_image} per image ({config.processing.patch_size[0]}×{config.processing.patch_size[1]})\"\n",
    "    )\n",
    "\n",
    "if config.spatial_coverage.three_d:\n",
    "    print(f\"   🧊 3D processing: Enabled\")\n",
    "\n",
    "print(f\"\\n📊 Processing scope: {'All images' if config.training.segment_all else f'{config.training.train_n} training + {config.training.validate_n} validation'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Validating project with ID 201...\n",
      "✅ Found project: foci_test\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline and preview what will be processed\n",
    "pipeline = create_pipeline(config, conn)\n",
    "\n",
    "# Get container details\n",
    "container_type = config.omero.container_type\n",
    "container_id = config.omero.container_id\n",
    "\n",
    "print(f\"🔍 Validating {container_type} with ID {container_id}...\")\n",
    "\n",
    "# Validate container exists\n",
    "container = conn.getObject(container_type.capitalize(), container_id)\n",
    "if container is None:\n",
    "    raise ValueError(f\"{container_type.capitalize()} with ID {container_id} not found\")\n",
    "\n",
    "print(f\"✅ Found {container_type}: {container.getName()}\")\n",
    "if container.getDescription():\n",
    "    print(f\"📝 Description: {container.getDescription()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero_annotate_ai.core.pipeline:Creating new tracking table: micro_sam_training_micro_sam_foci_test_20250823_104024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting annotation pipeline...\n",
      "   📊 Processing 10 images\n",
      "   🔬 Using micro-SAM model: vit_b_lm\n",
      "   ⚡ Processing: All images in one batch\n",
      "   🎨 Napari will open for interactive annotation\n",
      "   📝 Close napari windows when annotation is complete\n",
      "\n",
      "Creating annotation table\n",
      "Loading images from project 201\n",
      "Found 10 images\n",
      "Creating table for 10 images with model: vit_b_lm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero_annotate_ai.core.pipeline:ROI namespace: omero_annotate_ai.table.micro_sam_training_micro_sam_foci_test_20250823_104024\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(\"None\").astype(str)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(\"None\").astype(str)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(\"None\").astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Created tracking table 'micro_sam_training_micro_sam_foci_test_20250823_104024' with 4 units\n",
      "   Container: project 201\n",
      "   Table ID: 1346\n",
      "object group 0\n",
      "Stored configuration as annotation ID: 1347\n",
      "object group 0\n",
      "📊 Workflow status updated: 0/4 (0.0%) - pending\n",
      "Created annotation table with ID: 1346\n",
      "Starting annotation processing from table ID: 1346\n",
      "[TABLE] Getting unprocessed units from table 1346\n",
      "📋 Found 4 unprocessed units\n",
      "Found 4 processing units\n",
      "Processing batch 1/1\n",
      "📊 Loading 1 images using dask...\n",
      "💾 Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 25f41087-3d67-40c3-ab15-df082da3b40f/72735f5e-e022-4872-b206-2d1d934e854fomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Unregistered 25f41087-3d67-40c3-ab15-df082da3b40f/72735f5e-e022-4872-b206-2d1d934e854fomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Registered 25f41087-3d67-40c3-ab15-df082da3b40f/900240c3-bd35-467a-9e51-a120f6a333d5omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Unregistered 25f41087-3d67-40c3-ab15-df082da3b40f/900240c3-bd35-467a-9e51-a120f6a333d5omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 1 images\n",
      "📊 Loading 1 images using dask...\n",
      "💾 Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 25f41087-3d67-40c3-ab15-df082da3b40f/2bf52905-1cf3-47eb-a701-9c1df6dc3472omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 1 images\n",
      "📊 Loading 1 images using dask...\n",
      "💾 Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered 25f41087-3d67-40c3-ab15-df082da3b40f/2bf52905-1cf3-47eb-a701-9c1df6dc3472omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Registered 25f41087-3d67-40c3-ab15-df082da3b40f/cf9c194e-7ef4-46ff-939b-32edddbf46ebomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Unregistered 25f41087-3d67-40c3-ab15-df082da3b40f/cf9c194e-7ef4-46ff-939b-32edddbf46ebomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 1 images\n",
      "📊 Loading 1 images using dask...\n",
      "💾 Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n",
      "✅ Successfully loaded 1 images\n",
      "DEBUG: Ready to run micro_sam annotations\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Run the complete annotation pipeline\n",
    "print(\"🚀 Starting annotation pipeline...\")\n",
    "print(f\"   📊 Processing {len(images_list)} images\")\n",
    "print(f\"   🔬 Using micro-SAM model: {config.ai_model.model_type}\")\n",
    "\n",
    "if config.processing.batch_size == 0:\n",
    "    print(f\"   ⚡ Processing: All images in one batch\")\n",
    "else:\n",
    "    print(f\"   📦 Processing: Batches of {config.processing.batch_size} images\")\n",
    "\n",
    "print(f\"   🎨 Napari will open for interactive annotation\")\n",
    "print(f\"   📝 Close napari windows when annotation is complete\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Run the complete workflow - this is the key call!\n",
    "    table_id, processed_images = pipeline.run_full_workflow()\n",
    "    \n",
    "    print(f\"\\n🎉 Annotation pipeline completed successfully!\")\n",
    "    print(f\"📊 Processed {len(processed_images)} images\")\n",
    "    print(f\"📋 Tracking table ID: {table_id}\")\n",
    "    \n",
    "    if config.workflow.read_only_mode:\n",
    "        print(f\"💾 Annotations saved locally to: {config.output.output_directory}\")\n",
    "    else:\n",
    "        print(f\"☁️ Annotations uploaded to OMERO\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during annotation pipeline: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Pipeline Results Summary:\n",
      "   🎯 Training Set: micro_sam_annotation\n",
      "   📋 Tracking Table ID: 1331\n",
      "   📊 Images Processed: 10\n",
      "   📦 Container: project (ID: 201)\n",
      "   🔬 Model Used: vit_b_lm\n",
      "   📁 Output Location: c:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\examples\\omero_annotations\n",
      "\n",
      "🖼️ Processed Images:\n",
      "   1. 001_MAX_ExpMP2410_005_IB10#1_2h, Position001.tif (ID: 451)\n",
      "   2. 002_MAX_ExpMP2410_005_IB10#1_2h, Position002.tif (ID: 452)\n",
      "   3. 009_MAX_ExpMP2410_005_IB10#1_noIR, Position001.tif (ID: 453)\n",
      "   4. 010_MAX_ExpMP2410_005_IB10#1_noIR, Position002.tif (ID: 454)\n",
      "   5. 017_MAX_ExpMP2410_005_D3_noIR, Position001.tif (ID: 455)\n",
      "   6. 018_MAX_ExpMP2410_005_D3_noIR, Position002.tif (ID: 456)\n",
      "   7. 025_MAX_ExpMP2410_005_D3_2h, Position001.tif (ID: 457)\n",
      "   8. 026_MAX_ExpMP2410_005_D3_2h, Position002.tif (ID: 458)\n",
      "   9. 041_MAX_ExpMP2410_005_A2_noIR, Position001.tif (ID: 459)\n",
      "   10. 042_MAX_ExpMP2410_005_A2_noIR, Position002.tif (ID: 460)\n",
      "\n",
      "✅ Pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Display results summary\n",
    "print(\"📊 Pipeline Results Summary:\")\n",
    "print(f\"   🎯 Training Set: {config.name}\")\n",
    "print(f\"   📋 Tracking Table ID: {table_id}\")\n",
    "print(f\"   📊 Images Processed: {len(processed_images)}\")\n",
    "print(f\"   📦 Container: {config.omero.container_type} (ID: {config.omero.container_id})\")\n",
    "print(f\"   🔬 Model Used: {config.ai_model.model_type}\")\n",
    "print(f\"   📁 Output Location: {config.output.output_directory}\")\n",
    "\n",
    "# Show processed images\n",
    "if processed_images:\n",
    "    print(f\"\\n🖼️ Processed Images:\")\n",
    "    for i, img_obj in enumerate(processed_images[:10]):\n",
    "        if img_obj:\n",
    "            print(f\"   {i + 1}. {img_obj.getName()} (ID: {img_obj.getId()})\")\n",
    "\n",
    "    if len(processed_images) > 10:\n",
    "        print(f\"   ... and {len(processed_images) - 10} more images\")\n",
    "\n",
    "print(f\"\\n✅ Pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Configuration saved to: c:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\examples\\omero_annotations\\annotation_config_micro_sam_annotation.yaml\n",
      "\n",
      "📋 Configuration Summary:\n",
      "   Name: micro_sam_annotation\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AnnotationConfig' object has no attribute 'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📋 Configuration Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Description: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Output Directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39moutput_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Model Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mai_model\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\pydantic\\main.py:892\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AnnotationConfig' object has no attribute 'description'"
     ]
    }
   ],
   "source": [
    "# Export configuration for future use\n",
    "config_filename = f\"annotation_config_{config.name}.yaml\"\n",
    "config_path = Path(config.output.output_directory) / config_filename\n",
    "\n",
    "try:\n",
    "    config.save_yaml(config_path)\n",
    "    print(f\"💾 Configuration saved to: {config_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not save to output folder, saving to current directory\")\n",
    "    config.save_yaml(config_filename)\n",
    "    print(f\"💾 Configuration saved to: {config_filename}\")\n",
    "\n",
    "print(f\"\\n📋 Configuration Summary:\")\n",
    "print(f\"   Name: {config.name}\")\n",
    "print(f\"   Description: {config.description}\")\n",
    "print(f\"   Output Directory: {config.output.output_directory}\")\n",
    "print(f\"   Model Type: {config.ai_model.model_type}\")\n",
    "\n",
    "print(f\"\\n🔄 To reuse this configuration:\")\n",
    "print(f\"```python\")\n",
    "print(f\"from omero_annotate_ai import load_config\")\n",
    "print(f\"config = load_config('{config_filename}')\")\n",
    "print(f\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training widget\n",
    "from omero_annotate_ai import create_training_data_widget\n",
    "\n",
    "print(\"Training Data Selection\")\n",
    "print(\"Select existing annotation tables for training:\")\n",
    "print()\n",
    "\n",
    "# Create and display training data widget\n",
    "training_widget = create_training_data_widget(connection=conn)\n",
    "training_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected training table\n",
    "selected_table_id = training_widget.get_selected_table_id()\n",
    "selected_table_info = training_widget.get_selected_table_info()\n",
    "\n",
    "if selected_table_id:\n",
    "    print(f\"Selected training table:\")\n",
    "    print(f\"  Table ID: {selected_table_id}\")\n",
    "    print(f\"  Table Name: {selected_table_info.get('name', 'Unknown')}\")\n",
    "    print(f\"  Created: {selected_table_info.get('created', 'Unknown')}\")\n",
    "else:\n",
    "    print(\"No training table selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Preparation (Future)\n",
    "\n",
    "When the training data preparation function is implemented, you can use it like this:\n",
    "\n",
    "```python\n",
    "# Future implementation\n",
    "from omero_annotate_ai import prepare_training_data_from_table\n",
    "\n",
    "# Prepare training data automatically\n",
    "training_info = prepare_training_data_from_table(\n",
    "    conn=conn,\n",
    "    table_id=selected_table_id,\n",
    "    output_dir=\"./training_data\"\n",
    ")\n",
    "\n",
    "# Use training_info for micro-SAM training\n",
    "print(f\"Training data ready at: {training_info['paths']}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Close the OMERO connection when finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close OMERO connection\n",
    "if 'conn' in locals() and conn is not None:\n",
    "    conn.close()\n",
    "    print(\"🔌 OMERO connection closed\")\n",
    "\n",
    "print(f\"\\n🎉 Streamlined workflow completed!\")\n",
    "print(f\"📊 Total images processed: {len(processed_images) if 'processed_images' in locals() else 0}\")\n",
    "print(f\"💾 Configuration saved for future use\")\n",
    "print(f\"✨ Ready for next annotation workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
