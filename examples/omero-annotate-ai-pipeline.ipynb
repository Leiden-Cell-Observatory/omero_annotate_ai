{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMERO Micro-SAM Workflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ omero-annotate-ai version: 0.1.0\n",
      "ğŸ”— Available widgets: Connection, Workflow\n",
      "âœ¨ Streamlined 2-widget workflow ready!\n",
      "ğŸ”— OMERO functionality: âœ… Available\n",
      "ğŸ”‘ Keyring support: âœ… Available\n"
     ]
    }
   ],
   "source": [
    "# Import the streamlined package\n",
    "import omero_annotate_ai\n",
    "from omero_annotate_ai import (\n",
    "    create_omero_connection_widget,\n",
    "    create_workflow_widget,\n",
    "    create_pipeline\n",
    ")\n",
    "\n",
    "# System imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"ğŸ“¦ omero-annotate-ai version: {omero_annotate_ai.__version__}\")\n",
    "print(f\"ğŸ”— Available widgets: Connection, Workflow\")\n",
    "print(f\"âœ¨ Streamlined 2-widget workflow ready!\")\n",
    "\n",
    "# Check dependencies\n",
    "try:\n",
    "    import ezomero\n",
    "    print(f\"ğŸ”— OMERO functionality: âœ… Available\")\n",
    "except ImportError:\n",
    "    print(f\"ğŸ”— OMERO functionality: âŒ Install with: pip install -e .[omero]\")\n",
    "\n",
    "try:\n",
    "    import keyring\n",
    "    print(f\"ğŸ”‘ Keyring support: âœ… Available\")\n",
    "except ImportError:\n",
    "    print(f\"ğŸ”‘ Keyring support: âš ï¸ Not available (manual password entry only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OMERO Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ OMERO Connection Setup\n",
      "Use the widget below to connect to your OMERO server:\n",
      "  â€¢ Fill in server details (host, username, password)\n",
      "  â€¢ Test connection before proceeding\n",
      "  â€¢ Choose password storage duration if desired\n",
      "  â€¢ Click 'Save & Connect' to establish connection\n",
      "\n",
      "ğŸ“„ Loaded configuration from connection history: root@localhost\n",
      "ğŸ” Password loaded from keychain (no expiration)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140dbc70e0f34cecbe297eafacdd2974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ğŸ”Œ OMERO Server Connection</h3>', layout=Layout(margin='0 0 20px 0')), HTML(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Next Step: Run the cell below after connecting to OMERO\n"
     ]
    }
   ],
   "source": [
    "# Create and display the OMERO connection widget\n",
    "print(\"ğŸ”Œ OMERO Connection Setup\")\n",
    "print(\"Use the widget below to connect to your OMERO server:\")\n",
    "print(\"  â€¢ Fill in server details (host, username, password)\")\n",
    "print(\"  â€¢ Test connection before proceeding\")\n",
    "print(\"  â€¢ Choose password storage duration if desired\")\n",
    "print(\"  â€¢ Click 'Save & Connect' to establish connection\")\n",
    "print()\n",
    "\n",
    "conn_widget = create_omero_connection_widget()\n",
    "conn_widget.display()\n",
    "\n",
    "print(\"\\nğŸ“ Next Step: Run the cell below after connecting to OMERO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OMERO connection established!\n",
      "ğŸ‘¤ User: root\n",
      "ğŸ¢ Group: system\n",
      "ğŸ” Secure: True\n",
      "ğŸ”— Connection ready for workflow setup\n"
     ]
    }
   ],
   "source": [
    "# Get the OMERO connection\n",
    "conn = conn_widget.get_connection()\n",
    "\n",
    "if conn is None:\n",
    "    raise ConnectionError(\"âŒ No OMERO connection established. Please use the widget above to connect.\")\n",
    "\n",
    "print(\"âœ… OMERO connection established!\")\n",
    "print(f\"ğŸ‘¤ User: {conn.getUser().getName()}\")\n",
    "print(f\"ğŸ¢ Group: {conn.getGroupFromContext().getName()}\")\n",
    "print(f\"ğŸ” Secure: {conn.isSecure()}\")\n",
    "print(f\"ğŸ”— Connection ready for workflow setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Workflow Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¬ OMERO Annotation Workflow Setup\n",
      "Follow the sequential workflow below:\n",
      "  1. Select working directory\n",
      "  2. Choose OMERO container\n",
      "  3. Check existing annotation tables\n",
      "  4. Configure micro-SAM parameters\n",
      "  5. Save configuration\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7367cfa2f6244a3c859c56e1a1193de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ğŸ”¬ OMERO Annotation Workflow</h3>', layout=Layout(margin='0 0 20px 0')), IntProgâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Next Step: Complete the workflow above, then run the cell below\n"
     ]
    }
   ],
   "source": [
    "# Create and display the workflow widget\n",
    "print(\"ğŸ”¬ OMERO Annotation Workflow Setup\")\n",
    "print(\"Follow the sequential workflow below:\")\n",
    "print(\"  1. Select working directory\")\n",
    "print(\"  2. Choose OMERO container\")\n",
    "print(\"  3. Check existing annotation tables\")\n",
    "print(\"  4. Configure micro-SAM parameters\")\n",
    "print(\"  5. Save configuration\")\n",
    "print()\n",
    "\n",
    "workflow_widget = create_workflow_widget(connection=conn)\n",
    "workflow_widget.display()\n",
    "\n",
    "print(\"\\nğŸ“ Next Step: Complete the workflow above, then run the cell below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ Configuration Summary:\n",
      "   ğŸ“¦ Container: project (ID: 201)\n",
      "   ğŸ¯ Training Set: micro_sam_foci_test_20250823_104024\n",
      "   ğŸ”¬ Model: vit_b_lm\n",
      "   ğŸ“º Channel: [0]\n",
      "   ğŸ“ Output: c:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\examples\\omero_annotations_tmp\n",
      "   ğŸ”„ Resume from Table: False\n",
      "   ğŸ“– Read-only Mode: False\n",
      "\n",
      "ğŸ“Š Processing scope: 2 training + 2 validation\n"
     ]
    }
   ],
   "source": [
    "# Get configuration from workflow widget\n",
    "config = workflow_widget.get_config()\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"\\nğŸ“‹ Configuration Summary:\")\n",
    "print(f\"   ğŸ“¦ Container: {config.omero.container_type} (ID: {config.omero.container_id})\")\n",
    "print(f\"   ğŸ¯ Training Set: {config.name}\")\n",
    "print(f\"   ğŸ”¬ Model: {config.ai_model.model_type}\")\n",
    "print(f\"   ğŸ“º Channel: {config.spatial_coverage.channels}\")\n",
    "print(f\"   ğŸ“ Output: {config.output.output_directory}\")\n",
    "print(f\"   ğŸ”„ Resume from Table: {config.workflow.resume_from_table}\")\n",
    "print(f\"   ğŸ“– Read-only Mode: {config.workflow.read_only_mode}\")\n",
    "\n",
    "if config.processing.use_patches:\n",
    "    print(f\"   ğŸ§© Patches: {config.processing.patches_per_image} per image ({config.processing.patch_size[0]}Ã—{config.processing.patch_size[1]})\"\n",
    "    )\n",
    "\n",
    "if config.spatial_coverage.three_d:\n",
    "    print(f\"   ğŸ§Š 3D processing: Enabled\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Processing scope: {'All images' if config.training.segment_all else f'{config.training.train_n} training + {config.training.validate_n} validation'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Validating project with ID 201...\n",
      "âœ… Found project: foci_test\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline and preview what will be processed\n",
    "pipeline = create_pipeline(config, conn)\n",
    "\n",
    "# Get container details\n",
    "container_type = config.omero.container_type\n",
    "container_id = config.omero.container_id\n",
    "\n",
    "print(f\"ğŸ” Validating {container_type} with ID {container_id}...\")\n",
    "\n",
    "# Validate container exists\n",
    "container = conn.getObject(container_type.capitalize(), container_id)\n",
    "if container is None:\n",
    "    raise ValueError(f\"{container_type.capitalize()} with ID {container_id} not found\")\n",
    "\n",
    "print(f\"âœ… Found {container_type}: {container.getName()}\")\n",
    "if container.getDescription():\n",
    "    print(f\"ğŸ“ Description: {container.getDescription()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero_annotate_ai.core.pipeline:Creating new tracking table: micro_sam_training_micro_sam_foci_test_20250823_104024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting annotation pipeline...\n",
      "   ğŸ“Š Processing 10 images\n",
      "   ğŸ”¬ Using micro-SAM model: vit_b_lm\n",
      "   âš¡ Processing: All images in one batch\n",
      "   ğŸ¨ Napari will open for interactive annotation\n",
      "   ğŸ“ Close napari windows when annotation is complete\n",
      "\n",
      "Creating annotation table\n",
      "Loading images from project 201\n",
      "Found 10 images\n",
      "Creating table for 10 images with model: vit_b_lm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero_annotate_ai.core.pipeline:ROI namespace: omero_annotate_ai.table.micro_sam_training_micro_sam_foci_test_20250823_104024\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(\"None\").astype(str)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(\"None\").astype(str)\n",
      "c:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\omero_annotate_ai\\omero\\omero_functions.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(\"None\").astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Created tracking table 'micro_sam_training_micro_sam_foci_test_20250823_104024' with 4 units\n",
      "   Container: project 201\n",
      "   Table ID: 1346\n",
      "object group 0\n",
      "Stored configuration as annotation ID: 1347\n",
      "object group 0\n",
      "ğŸ“Š Workflow status updated: 0/4 (0.0%) - pending\n",
      "Created annotation table with ID: 1346\n",
      "Starting annotation processing from table ID: 1346\n",
      "[TABLE] Getting unprocessed units from table 1346\n",
      "ğŸ“‹ Found 4 unprocessed units\n",
      "Found 4 processing units\n",
      "Processing batch 1/1\n",
      "ğŸ“Š Loading 1 images using dask...\n",
      "ğŸ’¾ Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 25f41087-3d67-40c3-ab15-df082da3b40f/72735f5e-e022-4872-b206-2d1d934e854fomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Unregistered 25f41087-3d67-40c3-ab15-df082da3b40f/72735f5e-e022-4872-b206-2d1d934e854fomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Registered 25f41087-3d67-40c3-ab15-df082da3b40f/900240c3-bd35-467a-9e51-a120f6a333d5omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Unregistered 25f41087-3d67-40c3-ab15-df082da3b40f/900240c3-bd35-467a-9e51-a120f6a333d5omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully loaded 1 images\n",
      "ğŸ“Š Loading 1 images using dask...\n",
      "ğŸ’¾ Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 25f41087-3d67-40c3-ab15-df082da3b40f/2bf52905-1cf3-47eb-a701-9c1df6dc3472omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully loaded 1 images\n",
      "ğŸ“Š Loading 1 images using dask...\n",
      "ğŸ’¾ Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered 25f41087-3d67-40c3-ab15-df082da3b40f/2bf52905-1cf3-47eb-a701-9c1df6dc3472omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Registered 25f41087-3d67-40c3-ab15-df082da3b40f/cf9c194e-7ef4-46ff-939b-32edddbf46ebomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n",
      "INFO:omero.gateway:Unregistered 25f41087-3d67-40c3-ab15-df082da3b40f/cf9c194e-7ef4-46ff-939b-32edddbf46ebomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.8 -p 43859 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully loaded 1 images\n",
      "ğŸ“Š Loading 1 images using dask...\n",
      "ğŸ’¾ Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n",
      "âœ… Successfully loaded 1 images\n",
      "DEBUG: Ready to run micro_sam annotations\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Run the complete annotation pipeline\n",
    "print(\"ğŸš€ Starting annotation pipeline...\")\n",
    "print(f\"   ğŸ“Š Processing {len(images_list)} images\")\n",
    "print(f\"   ğŸ”¬ Using micro-SAM model: {config.ai_model.model_type}\")\n",
    "\n",
    "if config.processing.batch_size == 0:\n",
    "    print(f\"   âš¡ Processing: All images in one batch\")\n",
    "else:\n",
    "    print(f\"   ğŸ“¦ Processing: Batches of {config.processing.batch_size} images\")\n",
    "\n",
    "print(f\"   ğŸ¨ Napari will open for interactive annotation\")\n",
    "print(f\"   ğŸ“ Close napari windows when annotation is complete\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Run the complete workflow - this is the key call!\n",
    "    table_id, processed_images = pipeline.run_full_workflow()\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Annotation pipeline completed successfully!\")\n",
    "    print(f\"ğŸ“Š Processed {len(processed_images)} images\")\n",
    "    print(f\"ğŸ“‹ Tracking table ID: {table_id}\")\n",
    "    \n",
    "    if config.workflow.read_only_mode:\n",
    "        print(f\"ğŸ’¾ Annotations saved locally to: {config.output.output_directory}\")\n",
    "    else:\n",
    "        print(f\"â˜ï¸ Annotations uploaded to OMERO\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during annotation pipeline: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Pipeline Results Summary:\n",
      "   ğŸ¯ Training Set: micro_sam_annotation\n",
      "   ğŸ“‹ Tracking Table ID: 1331\n",
      "   ğŸ“Š Images Processed: 10\n",
      "   ğŸ“¦ Container: project (ID: 201)\n",
      "   ğŸ”¬ Model Used: vit_b_lm\n",
      "   ğŸ“ Output Location: c:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\examples\\omero_annotations\n",
      "\n",
      "ğŸ–¼ï¸ Processed Images:\n",
      "   1. 001_MAX_ExpMP2410_005_IB10#1_2h, Position001.tif (ID: 451)\n",
      "   2. 002_MAX_ExpMP2410_005_IB10#1_2h, Position002.tif (ID: 452)\n",
      "   3. 009_MAX_ExpMP2410_005_IB10#1_noIR, Position001.tif (ID: 453)\n",
      "   4. 010_MAX_ExpMP2410_005_IB10#1_noIR, Position002.tif (ID: 454)\n",
      "   5. 017_MAX_ExpMP2410_005_D3_noIR, Position001.tif (ID: 455)\n",
      "   6. 018_MAX_ExpMP2410_005_D3_noIR, Position002.tif (ID: 456)\n",
      "   7. 025_MAX_ExpMP2410_005_D3_2h, Position001.tif (ID: 457)\n",
      "   8. 026_MAX_ExpMP2410_005_D3_2h, Position002.tif (ID: 458)\n",
      "   9. 041_MAX_ExpMP2410_005_A2_noIR, Position001.tif (ID: 459)\n",
      "   10. 042_MAX_ExpMP2410_005_A2_noIR, Position002.tif (ID: 460)\n",
      "\n",
      "âœ… Pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Display results summary\n",
    "print(\"ğŸ“Š Pipeline Results Summary:\")\n",
    "print(f\"   ğŸ¯ Training Set: {config.name}\")\n",
    "print(f\"   ğŸ“‹ Tracking Table ID: {table_id}\")\n",
    "print(f\"   ğŸ“Š Images Processed: {len(processed_images)}\")\n",
    "print(f\"   ğŸ“¦ Container: {config.omero.container_type} (ID: {config.omero.container_id})\")\n",
    "print(f\"   ğŸ”¬ Model Used: {config.ai_model.model_type}\")\n",
    "print(f\"   ğŸ“ Output Location: {config.output.output_directory}\")\n",
    "\n",
    "# Show processed images\n",
    "if processed_images:\n",
    "    print(f\"\\nğŸ–¼ï¸ Processed Images:\")\n",
    "    for i, img_obj in enumerate(processed_images[:10]):\n",
    "        if img_obj:\n",
    "            print(f\"   {i + 1}. {img_obj.getName()} (ID: {img_obj.getId()})\")\n",
    "\n",
    "    if len(processed_images) > 10:\n",
    "        print(f\"   ... and {len(processed_images) - 10} more images\")\n",
    "\n",
    "print(f\"\\nâœ… Pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Configuration saved to: c:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\examples\\omero_annotations\\annotation_config_micro_sam_annotation.yaml\n",
      "\n",
      "ğŸ“‹ Configuration Summary:\n",
      "   Name: micro_sam_annotation\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AnnotationConfig' object has no attribute 'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ“‹ Configuration Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Description: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Output Directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39moutput_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Model Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mai_model\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\miniforge3\\envs\\micro-sam\\Lib\\site-packages\\pydantic\\main.py:892\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AnnotationConfig' object has no attribute 'description'"
     ]
    }
   ],
   "source": [
    "# Export configuration for future use\n",
    "config_filename = f\"annotation_config_{config.name}.yaml\"\n",
    "config_path = Path(config.output.output_directory) / config_filename\n",
    "\n",
    "try:\n",
    "    config.save_yaml(config_path)\n",
    "    print(f\"ğŸ’¾ Configuration saved to: {config_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not save to output folder, saving to current directory\")\n",
    "    config.save_yaml(config_filename)\n",
    "    print(f\"ğŸ’¾ Configuration saved to: {config_filename}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Configuration Summary:\")\n",
    "print(f\"   Name: {config.name}\")\n",
    "print(f\"   Description: {config.description}\")\n",
    "print(f\"   Output Directory: {config.output.output_directory}\")\n",
    "print(f\"   Model Type: {config.ai_model.model_type}\")\n",
    "\n",
    "print(f\"\\nğŸ”„ To reuse this configuration:\")\n",
    "print(f\"```python\")\n",
    "print(f\"from omero_annotate_ai import load_config\")\n",
    "print(f\"config = load_config('{config_filename}')\")\n",
    "print(f\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training widget\n",
    "from omero_annotate_ai import create_training_data_widget\n",
    "\n",
    "print(\"Training Data Selection\")\n",
    "print(\"Select existing annotation tables for training:\")\n",
    "print()\n",
    "\n",
    "# Create and display training data widget\n",
    "training_widget = create_training_data_widget(connection=conn)\n",
    "training_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected training table\n",
    "selected_table_id = training_widget.get_selected_table_id()\n",
    "selected_table_info = training_widget.get_selected_table_info()\n",
    "\n",
    "if selected_table_id:\n",
    "    print(f\"Selected training table:\")\n",
    "    print(f\"  Table ID: {selected_table_id}\")\n",
    "    print(f\"  Table Name: {selected_table_info.get('name', 'Unknown')}\")\n",
    "    print(f\"  Created: {selected_table_info.get('created', 'Unknown')}\")\n",
    "else:\n",
    "    print(\"No training table selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Preparation (Future)\n",
    "\n",
    "When the training data preparation function is implemented, you can use it like this:\n",
    "\n",
    "```python\n",
    "# Future implementation\n",
    "from omero_annotate_ai import prepare_training_data_from_table\n",
    "\n",
    "# Prepare training data automatically\n",
    "training_info = prepare_training_data_from_table(\n",
    "    conn=conn,\n",
    "    table_id=selected_table_id,\n",
    "    output_dir=\"./training_data\"\n",
    ")\n",
    "\n",
    "# Use training_info for micro-SAM training\n",
    "print(f\"Training data ready at: {training_info['paths']}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Close the OMERO connection when finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close OMERO connection\n",
    "if 'conn' in locals() and conn is not None:\n",
    "    conn.close()\n",
    "    print(\"ğŸ”Œ OMERO connection closed\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Streamlined workflow completed!\")\n",
    "print(f\"ğŸ“Š Total images processed: {len(processed_images) if 'processed_images' in locals() else 0}\")\n",
    "print(f\"ğŸ’¾ Configuration saved for future use\")\n",
    "print(f\"âœ¨ Ready for next annotation workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
