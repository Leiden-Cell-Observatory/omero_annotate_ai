{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMERO Micro-SAM Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omero-annotate-ai version: 0.1.0\n",
      "OMERO functionality: Available\n",
      "Keyring support: Available\n"
     ]
    }
   ],
   "source": [
    "import omero_annotate_ai\n",
    "from omero_annotate_ai import (\n",
    "    create_omero_connection_widget,\n",
    "    create_workflow_widget,\n",
    "    create_pipeline,\n",
    ")\n",
    "\n",
    "from omero_annotate_ai.core.config import load_config_from_yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"omero-annotate-ai version: {omero_annotate_ai.__version__}\")\n",
    "\n",
    "try:\n",
    "    import ezomero\n",
    "    print(\"OMERO functionality: Available\")\n",
    "except ImportError:\n",
    "    print(\"OMERO functionality: Install with: pip install -e .[omero]\")\n",
    "\n",
    "try:\n",
    "    import keyring\n",
    "    print(\"Keyring support: Available\")\n",
    "except ImportError:\n",
    "    print(\"Keyring support: Not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMERO Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Loaded configuration from connection history: root@localhost\n",
      "ğŸ” Password loaded from keychain (no expiration)\n",
      "ğŸ” Password loaded from keychain (no expiration)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d7e78b87c9441283b11eac7851ce33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ğŸ”Œ OMERO Server Connection</h3>', layout=Layout(margin='0 0 20px 0')), HTML(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn_widget = create_omero_connection_widget()\n",
    "conn_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected as: root\n",
      "Group: system\n"
     ]
    }
   ],
   "source": [
    "conn = conn_widget.get_connection()\n",
    "\n",
    "if conn is None:\n",
    "    raise ConnectionError(\"No OMERO connection established\")\n",
    "\n",
    "print(f\"Connected as: {conn.getUser().getName()}\")\n",
    "print(f\"Group: {conn.getGroupFromContext().getName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db1448bc32143c9a0739e34012b914d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ğŸ”¬ OMERO Annotation Workflow</h3>', layout=Layout(margin='0 0 20px 0')), IntProgâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the enhanced configuration widget with table management\n",
    "workflow_widget = create_workflow_widget(connection=conn)\n",
    "workflow_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container: project (ID: 201)\n",
      "Training Set: micro_sam_foci_test_20250815_090353\n",
      "Model: vit_b_lm\n",
      "Output: C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\n",
      "Patches: 1 per image (256Ã—256)\n",
      "Scope: 1 training + 1 validation\n"
     ]
    }
   ],
   "source": [
    "config = load_config_from_yaml(\n",
    "    \"C:\\\\Users\\\\Maarten\\\\AppData\\Local\\Temp\\\\omero_annotations_m_14q2cq\\\\annotation_config.yaml\"\n",
    ")\n",
    "\n",
    "config.validate()\n",
    "\n",
    "print(f\"Container: {config.omero.container_type} (ID: {config.omero.container_id})\")\n",
    "print(f\"Training Set: {config.training.trainingset_name}\")\n",
    "print(f\"Model: {config.micro_sam.model_type}\")\n",
    "print(f\"Output: {config.batch_processing.output_folder}\")\n",
    "\n",
    "if config.patches.use_patches:\n",
    "    print(f\"Patches: {config.patches.patches_per_image} per image ({config.patches.patch_size[0]}Ã—{config.patches.patch_size[1]})\")\n",
    "\n",
    "print(f\"Scope: {'All images' if config.training.segment_all else f'{config.training.train_n} training + {config.training.validate_n} validation'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container: foci_test\n",
      "ğŸ“ Loading images from project 201\n",
      "ğŸ“Š Found 10 images\n",
      "Images to process: 10\n",
      "  1. 001_MAX_ExpMP2410_005_IB10#1_2h, Position001.tif (ID: 451)\n",
      "  2. 002_MAX_ExpMP2410_005_IB10#1_2h, Position002.tif (ID: 452)\n",
      "  3. 009_MAX_ExpMP2410_005_IB10#1_noIR, Position001.tif (ID: 453)\n",
      "  ... and 7 more\n"
     ]
    }
   ],
   "source": [
    "pipeline = create_pipeline(config, conn)\n",
    "\n",
    "container = conn.getObject(config.omero.container_type.capitalize(), config.omero.container_id)\n",
    "if container is None:\n",
    "    raise ValueError(f\"{config.omero.container_type} with ID {config.omero.container_id} not found\")\n",
    "\n",
    "print(f\"Container: {container.getName()}\")\n",
    "\n",
    "images_list = pipeline.get_images_from_container()\n",
    "print(f\"Images to process: {len(images_list)}\")\n",
    "\n",
    "for i, img in enumerate(images_list[:3]):\n",
    "    print(f\"  {i+1}. {img.getName()} (ID: {img.getId()})\")\n",
    "if len(images_list) > 3:\n",
    "    print(f\"  ... and {len(images_list) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Creating annotation table\n",
      "ğŸ“Š Creating table for 10 images with model: vit_b_lm\n",
      "ğŸ“‹ Creating new tracking table: micro_sam_training_micro_sam_foci_test_20250815_090353\n",
      "ğŸ“‹ ROI namespace: omero_annotate_ai.table.micro_sam_training_micro_sam_foci_test_20250815_090353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\omero\\omero_functions.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).infer_objects(copy=False).astype(bool)\n",
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\omero\\omero_functions.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(\"None\").infer_objects(copy=False).astype(str)\n",
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\omero\\omero_functions.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(\"None\").infer_objects(copy=False).astype(str)\n",
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\omero\\omero_functions.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(\"None\").infer_objects(copy=False).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Created tracking table 'micro_sam_training_micro_sam_foci_test_20250815_090353' with 2 units\n",
      "   Container: project 201\n",
      "   Table ID: 1232\n",
      "object group 0\n",
      "Stored configuration as annotation ID: 1233\n",
      "object group 0\n",
      "ğŸ“Š Workflow status updated: 0/2 (0.0%) - pending\n",
      "ğŸ“‹ Created annotation table with ID: 1232\n",
      "Table created with ID: 1232\n",
      "ğŸš€ Starting annotation processing from table ID: 1232\n",
      "[TABLE] Getting unprocessed units from table 1232\n",
      "object group 0\n",
      "ğŸ“Š Workflow status updated: 0/2 (0.0%) - pending\n",
      "ğŸ“‹ Created annotation table with ID: 1232\n",
      "Table created with ID: 1232\n",
      "ğŸš€ Starting annotation processing from table ID: 1232\n",
      "[TABLE] Getting unprocessed units from table 1232\n",
      "ğŸ“‹ Found 2 unprocessed units\n",
      "ğŸ“‹ Found 2 processing units\n",
      "ğŸ”„ Processing batch 1/1\n",
      "ğŸ“Š Loading 1 images using dask...\n",
      "ğŸ’¾ Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n",
      "ğŸ“‹ Found 2 unprocessed units\n",
      "ğŸ“‹ Found 2 processing units\n",
      "ğŸ”„ Processing batch 1/1\n",
      "ğŸ“Š Loading 1 images using dask...\n",
      "ğŸ’¾ Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n",
      "âœ… Successfully loaded 1 images\n",
      "ğŸ“Š Loading 1 images using dask...\n",
      "ğŸ’¾ Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n",
      "âœ… Successfully loaded 1 images\n",
      "ğŸ“Š Loading 1 images using dask...\n",
      "ğŸ’¾ Materializing dask arrays to numpy...\n",
      "   Processing chunk 1/1\n",
      "âœ… Successfully loaded 1 images\n",
      "âœ… Successfully loaded 1 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precompute state for files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:22<00:00, 11.49s/it]\n",
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\core\\pipeline.py:377: UserWarning: Refusing to run a QApplication with no topLevelWidgets. To run the app anyway, use `run(force=True)`\n",
      "  napari.run()\n",
      "\n",
      "C:\\Users\\Maarten\\Documents\\Github\\omero_annotate_ai\\src\\omero_annotate_ai\\core\\pipeline.py:377: UserWarning: Refusing to run a QApplication with no topLevelWidgets. To run the app anyway, use `run(force=True)`\n",
      "  napari.run()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputation took 24.861404180526733 seconds (= 00:25 minutes)\n",
      "All images have already been annotated and you have set 'skip_segmented=True'. Nothing to do.\n",
      "ğŸ“ Found 2 annotation files in C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\n",
      "ğŸ” Step 1: Loading label image from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00000.tif\n",
      "ğŸ“‹ Label image loaded: (256, 256), dtype: uint32\n",
      "ğŸ·ï¸ Found 1 unique labels: [0]...\n",
      "ğŸ” Step 2: Converting labels to ROI shapes...\n",
      "âœ… Created 0 ROI shapes from labels\n",
      "ğŸ” Step 3: Uploading label file as attachment\n",
      "ğŸ“ Found 2 annotation files in C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\n",
      "ğŸ” Step 1: Loading label image from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00000.tif\n",
      "ğŸ“‹ Label image loaded: (256, 256), dtype: uint32\n",
      "ğŸ·ï¸ Found 1 unique labels: [0]...\n",
      "ğŸ” Step 2: Converting labels to ROI shapes...\n",
      "âœ… Created 0 ROI shapes from labels\n",
      "ğŸ” Step 3: Uploading label file as attachment\n",
      "âœ… File annotation uploaded with ID: 1235\n",
      "ğŸ” Step 4: Uploading ROI shapes\n",
      "âš ï¸ No ROI shapes created from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00000.tif\n",
      "â˜ï¸ Uploaded annotations from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00000.tif to image 459\n",
      "   Patch offset: (714, 525)\n",
      "   File annotation ID: 1235\n",
      "ğŸ” Step 1: Loading label image from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00001.tif\n",
      "ğŸ“‹ Label image loaded: (256, 256), dtype: uint32\n",
      "ğŸ·ï¸ Found 1 unique labels: [0]...\n",
      "ğŸ” Step 2: Converting labels to ROI shapes...\n",
      "âœ… Created 0 ROI shapes from labels\n",
      "ğŸ” Step 3: Uploading label file as attachment\n",
      "âœ… File annotation uploaded with ID: 1236\n",
      "ğŸ” Step 4: Uploading ROI shapes\n",
      "âš ï¸ No ROI shapes created from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00001.tif\n",
      "â˜ï¸ Uploaded annotations from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00001.tif to image 460\n",
      "   Patch offset: (476, 547)\n",
      "   File annotation ID: 1236\n",
      "âœ… File annotation uploaded with ID: 1235\n",
      "ğŸ” Step 4: Uploading ROI shapes\n",
      "âš ï¸ No ROI shapes created from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00000.tif\n",
      "â˜ï¸ Uploaded annotations from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00000.tif to image 459\n",
      "   Patch offset: (714, 525)\n",
      "   File annotation ID: 1235\n",
      "ğŸ” Step 1: Loading label image from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00001.tif\n",
      "ğŸ“‹ Label image loaded: (256, 256), dtype: uint32\n",
      "ğŸ·ï¸ Found 1 unique labels: [0]...\n",
      "ğŸ” Step 2: Converting labels to ROI shapes...\n",
      "âœ… Created 0 ROI shapes from labels\n",
      "ğŸ” Step 3: Uploading label file as attachment\n",
      "âœ… File annotation uploaded with ID: 1236\n",
      "ğŸ” Step 4: Uploading ROI shapes\n",
      "âš ï¸ No ROI shapes created from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00001.tif\n",
      "â˜ï¸ Uploaded annotations from C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\annotations\\seg_00001.tif to image 460\n",
      "   Patch offset: (476, 547)\n",
      "   File annotation ID: 1236\n",
      "Using table title: micro_sam_training_micro_sam_foci_test_20250815_090353\n",
      "ğŸ—‘ï¸ Deleting table: micro_sam_training_micro_sam_foci_test_20250815_090353\n",
      "Using table title: micro_sam_training_micro_sam_foci_test_20250815_090353\n",
      "ğŸ—‘ï¸ Deleting table: micro_sam_training_micro_sam_foci_test_20250815_090353\n",
      "âœ… Successfully deleted table 1232\n",
      "âœ… Successfully deleted table 1232\n",
      "ğŸ“‹ Table updated: 1232 â†’ 1237\n",
      "Using table title: micro_sam_training_micro_sam_foci_test_20250815_090353\n",
      "ğŸ—‘ï¸ Deleting table: micro_sam_training_micro_sam_foci_test_20250815_090353\n",
      "ğŸ“‹ Table updated: 1232 â†’ 1237\n",
      "Using table title: micro_sam_training_micro_sam_foci_test_20250815_090353\n",
      "ğŸ—‘ï¸ Deleting table: micro_sam_training_micro_sam_foci_test_20250815_090353\n",
      "âœ… Successfully deleted table 1237\n",
      "âœ… Successfully deleted table 1237\n",
      "ğŸ“‹ Table updated: 1237 â†’ 1238\n",
      "ğŸ“‹ Table updated: 1237 â†’ 1238\n",
      "ğŸ“¦ Created zip file: C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\embeddings_2.zip\n",
      "ğŸ—‘ï¸ Cleaned up embeddings: C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\embed\n",
      "object group 0\n",
      "ğŸ“¦ Created zip file: C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\embeddings_2.zip\n",
      "ğŸ—‘ï¸ Cleaned up embeddings: C:\\Users\\Maarten\\AppData\\Local\\Temp\\omero_annotations_m_14q2cq\\embed\n",
      "object group 0\n",
      "ğŸ“Š Workflow status updated: 2/2 (100.0%) - complete\n",
      "âœ… Completed batch 1 (2/2 total)\n",
      "ğŸ‰ Annotation processing completed successfully! Processed 2 units\n",
      "Completed. Processed 10 images\n",
      "Table ID: 1238\n",
      "ğŸ“Š Workflow status updated: 2/2 (100.0%) - complete\n",
      "âœ… Completed batch 1 (2/2 total)\n",
      "ğŸ‰ Annotation processing completed successfully! Processed 2 units\n",
      "Completed. Processed 10 images\n",
      "Table ID: 1238\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create annotation table\n",
    "table_id, images_list = pipeline.create_annotation_table(images_list)\n",
    "print(f\"Table created with ID: {table_id}\")\n",
    "\n",
    "# Step 2: Run annotation processing\n",
    "table_id, processed_images = pipeline.run_annotation(table_id, images_list)\n",
    "\n",
    "print(f\"Completed. Processed {len(processed_images)} images\")\n",
    "print(f\"Table ID: {table_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Set: {config.training.trainingset_name}\")\n",
    "print(f\"Table ID: {table_id}\")\n",
    "print(f\"Images Processed: {len(processed_images)}\")\n",
    "print(f\"Output: {config.batch_processing.output_folder}\")\n",
    "\n",
    "if processed_images:\n",
    "    print(f\"Processed Images:\")\n",
    "    for i, img in enumerate(processed_images[:5]):\n",
    "        if hasattr(img, 'getName'):\n",
    "            print(f\"  {i+1}. {img.getName()} (ID: {img.getId()})\")\n",
    "        else:\n",
    "            img_obj = conn.getObject(\"Image\", img)\n",
    "            if img_obj:\n",
    "                print(f\"  {i+1}. {img_obj.getName()} (ID: {img})\")\n",
    "    \n",
    "    if len(processed_images) > 5:\n",
    "        print(f\"  ... and {len(processed_images) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = f\"annotation_config_{config.training.trainingset_name}.yaml\"\n",
    "config_path = Path(config.batch_processing.output_folder) / config_filename\n",
    "\n",
    "try:\n",
    "    config.save_yaml(config_path)\n",
    "    print(f\"Config saved: {config_path}\")\n",
    "except Exception as e:\n",
    "    config.save_yaml(config_filename)\n",
    "    print(f\"Config saved: {config_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'conn' in locals() and conn is not None:\n",
    "    conn.close()\n",
    "    print(\"OMERO connection closed\")\n",
    "\n",
    "print(f\"Total images processed: {len(processed_images) if 'processed_images' in locals() else 0}\")\n",
    "print(f\"Table ID: {table_id if 'table_id' in locals() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Options\n",
    "\n",
    "```python\n",
    "# Option 1: Full workflow\n",
    "table_id, processed_images = pipeline.run_full_workflow()\n",
    "\n",
    "# Option 2: Split workflow\n",
    "table_id, images_list = pipeline.create_annotation_table()\n",
    "table_id, processed_images = pipeline.run_annotation(table_id, images_list)\n",
    "\n",
    "# Option 3: Resume from existing table\n",
    "table_id, processed_images = pipeline.run_annotation(existing_table_id)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
