{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro-SAM Training from OMERO Data\n",
    "\n",
    "Train micro-SAM models using annotation tables from OMERO with automated data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package with training convenience functions\n",
    "from omero_annotate_ai import (\n",
    "    create_omero_connection_widget,\n",
    "    create_training_data_widget,\n",
    "    prepare_training_data_from_table,\n",
    "    setup_training,    # Convenience function for training setup\n",
    "    run_training       # Convenience function for training execution\n",
    ")\n",
    "\n",
    "# Additional imports\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OMERO Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display OMERO connection widget\n",
    "conn_widget = create_omero_connection_widget()\n",
    "conn_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OMERO connection\n",
    "conn = conn_widget.get_connection()\n",
    "\n",
    "if conn is None:\n",
    "    raise ConnectionError(\"No OMERO connection established.\")\n",
    "\n",
    "print(f\"Connected to OMERO as: {conn.getUser().getName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data selection widget\n",
    "training_widget = create_training_data_widget(connection=conn)\n",
    "training_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected training table\n",
    "selected_table_id = training_widget.get_selected_table_id()\n",
    "selected_table_info = training_widget.get_selected_table_info()\n",
    "\n",
    "if selected_table_id:\n",
    "    print(f\"Selected training table:\")\n",
    "    print(f\"  Table ID: {selected_table_id}\")\n",
    "    print(f\"  Table Name: {selected_table_info.get('name', 'Unknown')}\")\n",
    "    print(f\"  Created: {selected_table_info.get('created', 'Unknown')}\")\n",
    "else:\n",
    "    raise ValueError(\"No training table selected. Please select a table above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Training Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for training\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "home_dir = Path.home()\n",
    "models_dir = home_dir / \"micro-sam_models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "folder_name = f\"micro-sam-{timestamp}\"\n",
    "output_directory = models_dir / folder_name\n",
    "output_directory.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Training output directory: {output_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Automated Data Preparation\n",
    "\n",
    "Use the automated data preparation function to download and organize training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run automated data preparation\n",
    "try:\n",
    "    training_result = prepare_training_data_from_table(\n",
    "        conn=conn,\n",
    "        table_id=selected_table_id,\n",
    "        training_name= selected_table_info.get('name', f\"training_table_{selected_table_id}\"),\n",
    "        output_dir=output_directory,\n",
    "        clean_existing=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining data preparation completed successfully!\")\n",
    "    print(f\"\\nDataset statistics:\")\n",
    "    for key, value in training_result['stats'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Store paths for later use in training\n",
    "    training_input_dir = training_result['training_input']\n",
    "    training_label_dir = training_result['training_label']\n",
    "    val_input_dir = training_result['val_input']\n",
    "    val_label_dir = training_result['val_label']\n",
    "    \n",
    "    print(f\"\\nDirectory structure created:\")\n",
    "    print(f\"  Training images: {training_input_dir}\")\n",
    "    print(f\"  Training labels: {training_label_dir}\")\n",
    "    print(f\"  Validation images: {val_input_dir}\")\n",
    "    print(f\"  Validation labels: {val_label_dir}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during data preparation: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Micro-SAM Training Setup\n",
    "\n",
    "Configure and run micro-SAM training using the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ¨ Setup training configuration using convenience function\n",
    "training_config = setup_training(\n",
    "    training_result,\n",
    "    model_name=f\"{selected_table_info.get('name', 'micro_sam_training')}_{timestamp}\",\n",
    "    epochs=10,               # Primary parameter: number of epochs (use 50+ for real training)\n",
    "    batch_size=1,            # Adjust based on GPU memory\n",
    "    learning_rate=1e-5,      # Conservative learning rate\n",
    "    patch_shape=(512, 512),  # Input patch size\n",
    "    model_type=\"vit_b_lm\",       # SAM model variant\n",
    "    n_objects_per_batch=25   # Objects per batch for sampling\n",
    ")\n",
    "\n",
    "print(\"Training configuration prepared!\")\n",
    "print(f'Model name: {training_config[\"model_name\"]}')\n",
    "print(f'Output directory: {training_config[\"output_dir\"]}')\n",
    "print(f'Training epochs: {training_config[\"epochs\"]}')\n",
    "print(f'Calculated iterations: {training_config[\"n_iterations\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ¨ Execute training with convenience function\n",
    "print(\"Starting micro-SAM training...\")\n",
    "\n",
    "training_results = run_training(training_config, framework=\"microsam\")\n",
    "\n",
    "print(f'ðŸŽ‰ Training completed successfully!')\n",
    "print(f'Training Results:')\n",
    "print(f'  Model name: {training_results[\"model_name\"]}')\n",
    "print(f'  Final model: {training_results.get(\"final_model_path\", \"Not available\")}')\n",
    "print(f'  Checkpoints saved: {len(training_results.get(\"checkpoints\", []))}')\n",
    "print(f'  Output directory: {training_results[\"output_dir\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Export and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best checkpoint\n",
    "checkpoints = list(checkpoint_folder.glob(\"*.pt\"))\n",
    "if checkpoints:\n",
    "    latest_checkpoint = sorted(checkpoints)[-1]\n",
    "    print(f\"Latest checkpoint: {latest_checkpoint}\")\n",
    "    \n",
    "    # Export model for inference\n",
    "    export_path = output_directory / f\"{model_name}_final.pt\"\n",
    "    print(f\"Model exported to: {export_path}\")\n",
    "else:\n",
    "    print(\"No checkpoints found.\")\n",
    "\n",
    "print(f\"\\nTraining summary:\")\n",
    "print(f\"  Output directory: {output_directory}\")\n",
    "print(f\"  Model name: {model_name}\")\n",
    "print(f\"  Training completed with {n_iterations} iterations\")\n",
    "print(f\"  Dataset statistics: {training_result['stats']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Union\n",
    "from micro_sam.bioimageio.model_export import export_sam_model\n",
    "import os\n",
    "from tifffile import imread\n",
    "import imageio.v3 as imageio\n",
    "import micro_sam.util as util\n",
    "from micro_sam.bioimageio.model_export import _create_test_inputs_and_outputs\n",
    "\n",
    "# Get a test image and label to use for exporting\n",
    "# For this example, we'll use the first image and label from validation set\n",
    "test_image_path = os.path.join(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_input\", os.listdir(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_input\")[0])\n",
    "test_label_path = os.path.join(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_label\", os.listdir(\"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\\\\val_label\")[0])\n",
    "output_directory = \"D:\\\\Maarten\\\\Data\\\\HR_sensor\\\\micro-sam-20250829_134050\"\n",
    "# Load the test image and label\n",
    "test_image = imageio.imread(test_image_path)\n",
    "test_label = np.array(imread(test_label_path))\n",
    "model_type=\"vit_b\"\n",
    "checkpoint_name = \"micro_sam_training_20250829_135659\"\n",
    "# Define the path for saving the bioimage.io model\n",
    "bioimageio_model_path = os.path.join(output_directory, \"bioimage_io_model\")\n",
    "#os.makedirs(bioimageio_model_path, exist_ok=True)\n",
    "\n",
    "# Export the SAM model to bioimage.io format\n",
    "export_sam_model(\n",
    "    image=test_image,\n",
    "    label_image=test_label,\n",
    "    model_type=model_type,  # Using the same model_type as in training\n",
    "    name=f\"micro_sam_test\",\n",
    "    output_path=bioimageio_model_path,\n",
    "    checkpoint_path=os.path.join(\n",
    "        output_directory, \"checkpoints\", checkpoint_name, \"best.pt\"\n",
    "    ),\n",
    "    # Optional: Add additional kwargs as needed\n",
    "    authors=[{\"name\": \"Your Name\", \"affiliation\": \"Your Institution\"}],\n",
    "    description=\"Micro-SAM model trained on microscopy images for segmentation\",\n",
    "    license=\"MIT\",\n",
    "    documentation=\"Model trained with micro-sam for segmenting microscopy images\",\n",
    ")\n",
    "\n",
    "print(f\"BioImage.IO model exported to: {bioimageio_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close OMERO connection\n",
    "if conn is not None:\n",
    "    conn.close()\n",
    "    print(\"OMERO connection closed.\")\n",
    "else:\n",
    "    print(\"No active OMERO connection to close.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-neu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
