{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro-SAM Run Inference on OMERO Data\n",
    "\n",
    "Example notebook to try the finetuned micro_sam model on OMERO data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup \n",
    "Run these cells to import all required packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the omero login widget\n",
    "from omero_annotate_ai import (\n",
    "    create_omero_connection_widget,\n",
    ")\n",
    "\n",
    "# Additional imports\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import ezomero\n",
    "import stackview\n",
    "import numpy as np\n",
    "\n",
    "from micro_sam.automatic_segmentation import get_predictor_and_segmenter, automatic_instance_segmentation\n",
    "\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_automatic_instance_segmentation(image, checkpoint_path, model_type=\"vit_b_lm\", device=None):\n",
    "    \"\"\"Automatic Instance Segmentation (AIS) by training an additional instance decoder in SAM.\n",
    "\n",
    "    NOTE: AIS is supported only for `µsam` models.\n",
    "\n",
    "    Args:\n",
    "        image: The input image.\n",
    "        checkpoint_path: The path to stored checkpoints.\n",
    "        model_type: The choice of the `µsam` model.\n",
    "        device: The device to run the model inference.\n",
    "\n",
    "    Returns:\n",
    "        The instance segmentation.\n",
    "    \"\"\"\n",
    "    # Step 1: Get the 'predictor' and 'segmenter' to perform automatic instance segmentation.\n",
    "    predictor, segmenter = get_predictor_and_segmenter(\n",
    "        model_type=model_type, # choice of the Segment Anything model\n",
    "        checkpoint=checkpoint_path,  # overwrite to pass your own finetuned model.\n",
    "        device=device,  # the device to run the model inference.\n",
    "    )\n",
    "\n",
    "    # Step 2: Get the instance segmentation for the given image.\n",
    "    prediction = automatic_instance_segmentation(\n",
    "        predictor=predictor,  # the predictor for the Segment Anything model.\n",
    "        segmenter=segmenter,  # the segmenter class responsible for generating predictions.\n",
    "        input_path=image,\n",
    "        ndim=2,\n",
    "    )\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OMERO Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display OMERO connection widget\n",
    "conn_widget = create_omero_connection_widget()\n",
    "conn_widget.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After setting up the setting we need to setup the OMERO connection\n",
    "conn = conn_widget.get_connection()\n",
    "\n",
    "if conn is None:\n",
    "    raise ConnectionError(\"No OMERO connection established.\")\n",
    "\n",
    "print(f\"Connected to OMERO as: {conn.getUser().getName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select image and a channel, timepoint z-slice (currently only 2D)\n",
    "image_id = 277\n",
    "channel = 0\n",
    "time_point = 66\n",
    "z_slice = 0\n",
    "checkpoint_path = r'micro_sam_training_20250829_135659_final.pt'\n",
    "\n",
    "#uncomment the line below to compare with original model before finetuning\n",
    "#checkpoint_path = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image from OMERO\n",
    "image = conn.getObject(\"Image\", image_id)\n",
    "__,pixels = ezomero.get_image(conn, image_id, start_coords=[0,0,z_slice,channel,time_point], axis_lengths=[image.getSizeX(),image.getSizeY(),1,1,1])\n",
    "#Run prediction\n",
    "labels = run_automatic_instance_segmentation(np.squeeze(pixels), checkpoint_path, model_type=\"vit_b_lm\", device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you can see your image with labels overlayed\n",
    "stackview.curtain(np.squeeze(pixels), labels, alpha=0.5, continuous_update=True,zoom_factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example how you can run the prediction on a stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select image\n",
    "image_id = 277\n",
    "channel = 0\n",
    "time_point = 0\n",
    "time_point_length = 30\n",
    "z_slice = 0\n",
    "checkpoint_path = r'micro_sam_training_20250829_135659_final.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image from OMERO\n",
    "image = conn.getObject(\"Image\", image_id)\n",
    "__,pixels = ezomero.get_image(conn, image_id, start_coords=[0,0,z_slice,channel,time_point], axis_lengths=[image.getSizeX(),image.getSizeY(),1,1,time_point_length])\n",
    "#Run prediction\n",
    "labels = []\n",
    "for i in range(np.shape(pixels)[0]):\n",
    "    labels.append(run_automatic_instance_segmentation(np.squeeze(pixels[i]), checkpoint_path, model_type=\"vit_b_lm\", device=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now you can also slice through the images\n",
    "stackview.curtain(np.squeeze(pixels), labels, alpha=0.5, continuous_update=True,zoom_factor=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
